{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f484d47-83b6-41d0-bf35-9cdfc14e7497",
      "metadata": {
        "id": "4f484d47-83b6-41d0-bf35-9cdfc14e7497"
      },
      "outputs": [],
      "source": [
        "# === Cell 1: imports & dataclasses ===\n",
        "from __future__ import annotations\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple, Callable\n",
        "\n",
        "Array = np.ndarray\n",
        "\n",
        "@dataclass\n",
        "class AMCPaths:\n",
        "    S: Array                 # (P, M+1)\n",
        "    Z: Optional[Array]       # (P, M)\n",
        "    t: Array                 # (M+1,)    t[0]=0, t[-1]=T\n",
        "    disc: float              # exp(-r*dt)\n",
        "    dt: float                # T/M\n",
        "    r: float                 # risk-free rate\n",
        "    q: float                 # dividend yield\n",
        "    sigma: float             # volatility\n",
        "    S0: float                # initial price\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5430a94a-6077-4281-8607-749c2288abbd",
      "metadata": {
        "id": "5430a94a-6077-4281-8607-749c2288abbd"
      },
      "outputs": [],
      "source": [
        "# === Cell 2: antithetic normals & GBM paths ===\n",
        "def make_Z_antithetic(P: int, M: int, seed: Optional[int] = None, dtype=np.float64) -> Array:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    half = (P + 1) // 2\n",
        "    Zh = rng.standard_normal((half, M), dtype=dtype)\n",
        "    Z  = np.concatenate([Zh, -Zh], axis=0)[:P, :]\n",
        "    return Z\n",
        "\n",
        "def simulate_gbm_paths(\n",
        "    S0: float, r: float, q: float, sigma: float, T: float, M: int, P: int,\n",
        "    *, seed: Optional[int] = None, antithetic: bool = True, return_Z: bool = True,\n",
        "    dtype=np.float64, Z: Optional[Array] = None,\n",
        ") -> AMCPaths:\n",
        "    if M <= 0 or P <= 0:\n",
        "        raise ValueError(\"M and P must be positive.\")\n",
        "    if sigma < 0: raise ValueError(\"sigma must be nonnegative.\")\n",
        "    if T < 0: raise ValueError(\"T must be nonnegative.\")\n",
        "\n",
        "    dt = T / M\n",
        "    t  = np.linspace(0.0, T, M + 1, dtype=dtype)\n",
        "    mu_step  = (r - q - 0.5 * sigma * sigma) * dt\n",
        "    vol_step = sigma * np.sqrt(dt)\n",
        "\n",
        "    if Z is not None:\n",
        "        Z_used = np.asarray(Z, dtype=dtype)\n",
        "        if Z_used.shape != (P, M):\n",
        "            raise ValueError(f\"Z must have shape (P,M)=({P},{M})\")\n",
        "    else:\n",
        "        if antithetic:\n",
        "            Z_used = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "        else:\n",
        "            rng = np.random.default_rng(seed)\n",
        "            Z_used = rng.standard_normal((P, M), dtype=dtype)\n",
        "\n",
        "    log_inc = mu_step + vol_step * Z_used\n",
        "    np.cumsum(log_inc, axis=1, out=log_inc)\n",
        "    S = np.empty((P, M + 1), dtype=dtype)\n",
        "    S[:, 0]  = S0\n",
        "    np.exp(log_inc, out=log_inc)\n",
        "    S[:, 1:] = S0 * log_inc\n",
        "\n",
        "    disc = float(np.exp(-r * dt))\n",
        "    return AMCPaths(S=S, Z=Z_used if return_Z else None, t=t, disc=disc, dt=dt,\n",
        "                    r=r, q=q, sigma=sigma, S0=S0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1412f478-3856-4cd9-82c9-f1fb00e2980c",
      "metadata": {
        "id": "1412f478-3856-4cd9-82c9-f1fb00e2980c"
      },
      "outputs": [],
      "source": [
        "# === Cell 3: Local Vol ===\n",
        "@dataclass\n",
        "class LocalVolSurface:\n",
        "    t_grid: np.ndarray        # (Nt,)\n",
        "    s_grid: np.ndarray        # (Ns,)\n",
        "    sigma_table: np.ndarray   # (Nt, Ns)\n",
        "    floor: float = 0.02\n",
        "    cap: float   = 3.00\n",
        "\n",
        "    def sigma(self, s: float, t: float) -> float:\n",
        "        t = float(np.clip(t, self.t_grid[0], self.t_grid[-1]))\n",
        "        s = float(np.clip(s, self.s_grid[0], self.s_grid[-1]))\n",
        "        i = np.searchsorted(self.t_grid, t)\n",
        "        j = np.searchsorted(self.s_grid, s)\n",
        "        i0 = max(0, min(i-1, len(self.t_grid)-1)); i1 = max(0, min(i, len(self.t_grid)-1))\n",
        "        j0 = max(0, min(j-1, len(self.s_grid)-1)); j1 = max(0, min(j, len(self.s_grid)-1))\n",
        "        wt = 0.0 if i1==i0 else (t - self.t_grid[i0])/(self.t_grid[i1]-self.t_grid[i0])\n",
        "        ws = 0.0 if j1==j0 else (s - self.s_grid[j0])/(self.s_grid[j1]-self.s_grid[j0])\n",
        "        sig0 = (1-ws)*self.sigma_table[i0, j0] + ws*self.sigma_table[i0, j1]\n",
        "        sig1 = (1-ws)*self.sigma_table[i1, j0] + ws*self.sigma_table[i1, j1]\n",
        "        sig  = (1-wt)*sig0 + wt*sig1\n",
        "        return float(np.clip(sig, self.floor, self.cap))\n",
        "\n",
        "def simulate_localvol_paths(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    lv: LocalVolSurface, *, seed: int | None = None, Z: np.ndarray | None = None,\n",
        ") -> AMCPaths:\n",
        "    dtype = np.float64\n",
        "    if M <= 0 or P <= 0: raise ValueError(\"M and P must be positive.\")\n",
        "    dt = T / M\n",
        "    t  = np.linspace(0.0, T, M + 1, dtype=dtype)\n",
        "    sqrt_dt = np.sqrt(dt, dtype=dtype)\n",
        "\n",
        "    if Z is not None:\n",
        "        Z_used = np.asarray(Z, dtype=dtype)\n",
        "        if Z_used.shape != (P, M):\n",
        "            raise ValueError(f\"Z must have shape (P,M)=({P},{M})\")\n",
        "    else:\n",
        "        Z_used = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "\n",
        "    S = np.empty((P, M+1), dtype=dtype); S[:, 0] = S0\n",
        "    for i in range(M):\n",
        "        ti   = t[i]\n",
        "        sig0 = np.array([lv.sigma(s, ti) for s in S[:, i]], dtype=dtype)\n",
        "        mu0  = (r - q) - 0.5*sig0**2\n",
        "        S_star = S[:, i] * np.exp(mu0*dt + sig0*sqrt_dt*Z_used[:, i])\n",
        "        sig1 = np.array([lv.sigma(s, ti+dt) for s in S_star], dtype=dtype)\n",
        "        sig  = 0.5*(sig0 + sig1)\n",
        "        mu   = (r - q) - 0.5*sig**2\n",
        "        S[:, i+1] = S[:, i] * np.exp(mu*dt + sig*sqrt_dt*Z_used[:, i])\n",
        "\n",
        "    disc = float(np.exp(-r * dt))\n",
        "    return AMCPaths(S=S, Z=Z_used, t=t, disc=disc, dt=dt, r=r, q=q, sigma=float(\"nan\"), S0=S0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9ee3779-7bf3-4dd6-926f-848a2a74d1f3",
      "metadata": {
        "id": "b9ee3779-7bf3-4dd6-926f-848a2a74d1f3"
      },
      "outputs": [],
      "source": [
        "# === Cell 4: Heston & SLV ===\n",
        "def _heston_qe_step(v: np.ndarray, kappa: float, theta: float, sigma_v: float, dt: float, Z: np.ndarray) -> np.ndarray:\n",
        "    m  = theta + (v - theta)*np.exp(-kappa*dt)\n",
        "    s2 = (v*sigma_v**2*np.exp(-kappa*dt)/kappa)*(1-np.exp(-kappa*dt)) \\\n",
        "       + theta*sigma_v**2*(1-np.exp(-kappa*dt))**2/(2*kappa)\n",
        "    psi = s2/np.maximum(m, 1e-16)**2\n",
        "    v_next = np.empty_like(v); psi_c = 1.5\n",
        "    i1 = psi <= psi_c\n",
        "    if np.any(i1):\n",
        "        b2 = 2/psi[i1] - 1 + np.sqrt(2/psi[i1]) * np.sqrt(2/psi[i1]-1)\n",
        "        a  = m[i1]/(1+b2)\n",
        "        v_next[i1] = a*(np.sqrt(b2)+Z[i1])**2\n",
        "    i2 = ~i1\n",
        "    if np.any(i2):\n",
        "        p  = (psi[i2]-1)/(psi[i2]+1); beta = (1-p)/m[i2]\n",
        "        U  = 0.5*(Z[i2]+1.0)\n",
        "        v_next[i2] = np.where(U<=p, 0.0, -np.log((1-p)/(1-U))/beta)\n",
        "    return np.maximum(v_next, 0.0)\n",
        "\n",
        "def simulate_heston_paths(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    *, kappa: float, theta: float, sigma_v: float, rho: float, v0: float,\n",
        "    seed: int | None = None, Zs: np.ndarray | None = None, Zv: np.ndarray | None = None\n",
        ") -> AMCPaths:\n",
        "    dtype = np.float64\n",
        "    if M <= 0 or P <= 0: raise ValueError(\"M and P must be positive.\")\n",
        "    dt = T / M\n",
        "    t  = np.linspace(0.0, T, M + 1, dtype=dtype)\n",
        "    sqrt_dt = np.sqrt(dt, dtype=dtype)\n",
        "\n",
        "    if (Zs is None) or (Zv is None):\n",
        "        Z1 = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "        Z2 = make_Z_antithetic(P, M, seed=None, dtype=dtype)\n",
        "        Zv_used = Z2\n",
        "        Zs_used = rho*Z2 + np.sqrt(max(1.0 - rho*rho, 0.0))*Z1\n",
        "    else:\n",
        "        Zs_used = np.asarray(Zs, dtype=dtype); Zv_used = np.asarray(Zv, dtype=dtype)\n",
        "        if Zs_used.shape!=(P,M) or Zv_used.shape!=(P,M):\n",
        "            raise ValueError(\"Zs/Zv must be shape (P,M)\")\n",
        "\n",
        "    S = np.empty((P, M+1), dtype=dtype); S[:,0] = S0\n",
        "    v = np.empty((P, M+1), dtype=dtype); v[:,0] = max(v0, 1e-12)\n",
        "\n",
        "    for i in range(M):\n",
        "        v[:,i+1] = _heston_qe_step(v[:,i], kappa, theta, sigma_v, dt, Zv_used[:,i])\n",
        "        diff = np.sqrt(np.maximum(v[:,i], 0.0))\n",
        "        mu   = (r - q) - 0.5*diff**2\n",
        "        S[:,i+1] = S[:,i] * np.exp(mu*dt + diff*sqrt_dt*Zs_used[:,i])\n",
        "\n",
        "    disc = float(np.exp(-r * dt))\n",
        "    return AMCPaths(S=S, Z=Zs_used, t=t, disc=disc, dt=dt, r=r, q=q, sigma=float(\"nan\"), S0=S0)\n",
        "\n",
        "def simulate_slv_paths(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    *, lv: LocalVolSurface, kappa: float, theta: float, sigma_v: float, rho: float, v0: float,\n",
        "    seed: int | None = None, Zs: np.ndarray | None = None, Zv: np.ndarray | None = None\n",
        ") -> AMCPaths:\n",
        "    dtype = np.float64\n",
        "    if M <= 0 or P <= 0: raise ValueError(\"M and P must be positive.\")\n",
        "    dt = T / M\n",
        "    t  = np.linspace(0.0, T, M + 1, dtype=dtype)\n",
        "    sqrt_dt = np.sqrt(dt, dtype=dtype)\n",
        "\n",
        "    if (Zs is None) or (Zv is None):\n",
        "        Z1 = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "        Z2 = make_Z_antithetic(P, M, seed=None, dtype=dtype)\n",
        "        Zv_used = Z2\n",
        "        Zs_used = rho*Z2 + np.sqrt(max(1.0 - rho*rho, 0.0))*Z1\n",
        "    else:\n",
        "        Zs_used = np.asarray(Zs, dtype=dtype); Zv_used = np.asarray(Zv, dtype=dtype)\n",
        "        if Zs_used.shape!=(P,M) or Zv_used.shape!=(P,M):\n",
        "            raise ValueError(\"Zs/Zv must be shape (P,M)\")\n",
        "\n",
        "    S = np.empty((P, M+1), dtype=dtype); S[:,0] = S0\n",
        "    v = np.empty((P, M+1), dtype=dtype); v[:,0] = max(v0, 1e-12)\n",
        "\n",
        "    for i in range(M):\n",
        "        v[:,i+1] = _heston_qe_step(v[:,i], kappa, theta, sigma_v, dt, Zv_used[:,i])\n",
        "        sig_lv = np.array([lv.sigma(s, t[i]) for s in S[:, i]], dtype=dtype)\n",
        "        diff   = sig_lv * np.sqrt(np.maximum(v[:,i], 0.0))\n",
        "        mu     = (r - q) - 0.5*diff**2\n",
        "        S[:,i+1] = S[:,i] * np.exp(mu*dt + diff*sqrt_dt*Zs_used[:,i])\n",
        "\n",
        "    disc = float(np.exp(-r * dt))\n",
        "    return AMCPaths(S=S, Z=Zs_used, t=t, disc=disc, dt=dt, r=r, q=q, sigma=float(\"nan\"), S0=S0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "523c1f7c-61ef-4db2-a123-790511c54e8d",
      "metadata": {
        "id": "523c1f7c-61ef-4db2-a123-790511c54e8d"
      },
      "outputs": [],
      "source": [
        "# === Cell 5: antithetic dispatchers ===\n",
        "def prepare_antithetic_paths_for_american_gbm(\n",
        "    S0: float, r: float, q: float, sigma: float, T: float, M: int, P: int,\n",
        "    *, seed: Optional[int] = None, dtype=np.float64,\n",
        ") -> Tuple[AMCPaths, AMCPaths]:\n",
        "    Z = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "    pack_pos = simulate_gbm_paths(S0, r, q, sigma, T, M, P, seed=None,\n",
        "                                  antithetic=False, return_Z=True, dtype=dtype, Z=Z)\n",
        "    pack_neg = simulate_gbm_paths(S0, r, q, sigma, T, M, P, seed=None,\n",
        "                                  antithetic=False, return_Z=True, dtype=dtype, Z=-Z)\n",
        "    return pack_pos, pack_neg\n",
        "\n",
        "def prepare_antithetic_paths_for_american_lv(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int, lv: LocalVolSurface,\n",
        "    *, seed: Optional[int] = None, dtype=np.float64,\n",
        ") -> Tuple[AMCPaths, AMCPaths]:\n",
        "    Z = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "    pack_pos = simulate_localvol_paths(S0, r, q, T, M, P, lv, seed=None, Z=Z)\n",
        "    pack_neg = simulate_localvol_paths(S0, r, q, T, M, P, lv, seed=None, Z=-Z)\n",
        "    return pack_pos, pack_neg\n",
        "\n",
        "def prepare_antithetic_paths_for_american_heston(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    *, kappa: float, theta: float, sigma_v: float, rho: float, v0: float,\n",
        "    seed: Optional[int] = None, dtype=np.float64,\n",
        ") -> Tuple[AMCPaths, AMCPaths]:\n",
        "    Z1 = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "    Z2 = make_Z_antithetic(P, M, seed=None, dtype=dtype)\n",
        "    Zs = rho * Z2 + np.sqrt(max(1.0 - rho*rho, 0.0)) * Z1\n",
        "    Zv = Z2\n",
        "    pack_pos = simulate_heston_paths(S0, r, q, T, M, P,\n",
        "                                     kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                     rho=rho, v0=v0, Zs=Zs, Zv=Zv)\n",
        "    pack_neg = simulate_heston_paths(S0, r, q, T, M, P,\n",
        "                                     kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                     rho=rho, v0=v0, Zs=-Zs, Zv=-Zv)\n",
        "    return pack_pos, pack_neg\n",
        "\n",
        "def prepare_antithetic_paths_for_american_slv(\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    *, lv: LocalVolSurface, kappa: float, theta: float, sigma_v: float, rho: float, v0: float,\n",
        "    seed: Optional[int] = None, dtype=np.float64,\n",
        ") -> Tuple[AMCPaths, AMCPaths]:\n",
        "    Z1 = make_Z_antithetic(P, M, seed=seed, dtype=dtype)\n",
        "    Z2 = make_Z_antithetic(P, M, seed=None, dtype=dtype)\n",
        "    Zs = rho * Z2 + np.sqrt(max(1.0 - rho*rho, 0.0)) * Z1\n",
        "    Zv = Z2\n",
        "    pack_pos = simulate_slv_paths(S0, r, q, T, M, P,\n",
        "                                  lv=lv, kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                  rho=rho, v0=v0, Zs=Zs, Zv=Zv)\n",
        "    pack_neg = simulate_slv_paths(S0, r, q, T, M, P,\n",
        "                                  lv=lv, kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                  rho=rho, v0=v0, Zs=-Zs, Zv=-Zv)\n",
        "    return pack_pos, pack_neg\n",
        "\n",
        "def prepare_antithetic_paths_for_american(\n",
        "    mode: str,\n",
        "    S0: float, r: float, q: float, T: float, M: int, P: int,\n",
        "    *, sigma: float = None, lv: LocalVolSurface = None,\n",
        "    kappa: float = None, theta: float = None, sigma_v: float = None, rho: float = None, v0: float = None,\n",
        "    seed: Optional[int] = None, dtype=np.float64,\n",
        ") -> Tuple[AMCPaths, AMCPaths]:\n",
        "    if mode == \"GBM\":\n",
        "        return prepare_antithetic_paths_for_american_gbm(S0, r, q, sigma, T, M, P, seed=seed, dtype=dtype)\n",
        "    elif mode == \"LV\":\n",
        "        return prepare_antithetic_paths_for_american_lv(S0, r, q, T, M, P, lv, seed=seed, dtype=dtype)\n",
        "    elif mode == \"Heston\":\n",
        "        return prepare_antithetic_paths_for_american_heston(S0, r, q, T, M, P,\n",
        "                                                            kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                                            rho=rho, v0=v0, seed=seed, dtype=dtype)\n",
        "    elif mode == \"SLV\":\n",
        "        return prepare_antithetic_paths_for_american_slv(S0, r, q, T, M, P,\n",
        "                                                         lv=lv, kappa=kappa, theta=theta, sigma_v=sigma_v,\n",
        "                                                         rho=rho, v0=v0, seed=seed, dtype=dtype)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model {mode}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173ac82f-1d04-4112-bed2-54a467add710",
      "metadata": {
        "id": "173ac82f-1d04-4112-bed2-54a467add710"
      },
      "outputs": [],
      "source": [
        "# === Cell 6: LSM ===\n",
        "# ===== Smooth utilities (shared by forward LSM & AAD) =====\n",
        "TAU = 0.10\n",
        "\n",
        "def _softplus_np(x):\n",
        "    # oftplus(x) = log1p(exp(x))\n",
        "    return np.where(x > 20, x, np.log1p(np.exp(x)))\n",
        "\n",
        "def _sigmoid_np(x):\n",
        "    # σ(x) = 1/(1+e^{-x})\n",
        "    return 1.0 / (1.0 + np.exp(-x))\n",
        "\n",
        "def smooth_max_np(a, b, tau=TAU):\n",
        "    # max(a,b) ≈ b + tau * softplus((a-b)/tau)\n",
        "    return b + tau * _softplus_np((a - b) / tau)\n",
        "\n",
        "def _ols_beta(X: Array, y: Array) -> Array:\n",
        "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
        "    return beta\n",
        "\n",
        "def basis_poly2(x: Array) -> Array:\n",
        "    x = np.asarray(x).reshape(-1, 1)\n",
        "    return np.column_stack([np.ones_like(x), x, x**2])\n",
        "\n",
        "def basis_poly3(x: Array) -> Array:\n",
        "    x = np.asarray(x).reshape(-1, 1)\n",
        "    return np.column_stack([np.ones_like(x), x, x**2, x**3])\n",
        "\n",
        "def payoff_call_now(S_slice: Array, K: float, tau: float = TAU) -> Array:\n",
        "    # max(S-K,0)tau * softplus((S-K)/tau)\n",
        "    return tau * _softplus_np((S_slice - K) / tau)\n",
        "\n",
        "def payoff_put_now(S_slice: Array, K: float, tau: float = TAU) -> Array:\n",
        "    return tau * _softplus_np((K - S_slice) / tau)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LSMResult:\n",
        "    price: float\n",
        "    stderr: float\n",
        "    C_path: Array\n",
        "    exercised: Array\n",
        "    tau_idx: Array\n",
        "    r2: Array\n",
        "    itm_counts: Array\n",
        "    betas: list\n",
        "    near_boundary_mask: Optional[Array] = None\n",
        "\n",
        "def _lsm_single_pack(\n",
        "    pack: AMCPaths, K: float,\n",
        "    payoff_now: Callable[[Array, float], Array],\n",
        "    basis_fn: Callable[[Array], Array] = basis_poly3,\n",
        ") -> LSMResult:\n",
        "    S, dt, disc = pack.S, pack.dt, pack.disc\n",
        "    P, M1 = S.shape\n",
        "    M = M1 - 1\n",
        "\n",
        "    # continuation value container at each path (starting from maturity)\n",
        "    C = payoff_now(S[:, M], K).astype(S.dtype, copy=False)\n",
        "\n",
        "    r2_list, itm_list = [], []\n",
        "    betas_list = []\n",
        "    betas_by_m = [None] * (M + 1)\n",
        "    tau_idx = np.zeros(P, dtype=np.int32)\n",
        "    exercised = np.zeros(P, dtype=bool)\n",
        "\n",
        "    # Backward induction (M-1 ... 1)\n",
        "    for m in range(M - 1, 0, -1):\n",
        "        Sm = S[:, m]\n",
        "        E  = payoff_now(Sm, K)\n",
        "        itm = (E > 0.0)\n",
        "        itm_list.append(int(itm.sum()))\n",
        "\n",
        "        if np.any(itm):\n",
        "            X = basis_fn(Sm[itm])\n",
        "            y = disc * C[itm]\n",
        "            beta = _ols_beta(X, y)\n",
        "            betas_list.append(beta)\n",
        "            betas_by_m[m] = beta\n",
        "\n",
        "            y_hat = X @ beta\n",
        "            ss_res = np.sum((y - y_hat)**2)\n",
        "            ss_tot = np.sum((y - y.mean())**2) if y.size > 1 else np.nan\n",
        "            r2 = 1.0 - ss_res / ss_tot if np.isfinite(ss_tot) and ss_tot > 0 else np.nan\n",
        "            r2_list.append(r2)\n",
        "\n",
        "            C_hat = np.zeros(P, dtype=S.dtype)\n",
        "            C_hat[itm] = (basis_fn(Sm[itm]) @ beta)\n",
        "        else:\n",
        "            # keep shapes consistent even when no ITM\n",
        "            empty_beta = np.full(basis_fn(np.array([0.0])).shape[1], np.nan)\n",
        "            betas_list.append(empty_beta)\n",
        "            betas_by_m[m] = None\n",
        "            r2_list.append(np.nan)\n",
        "            C_hat = np.zeros(P, dtype=S.dtype)\n",
        "                    # ----- Smooth decision: blend between exercise and continue -----\n",
        "        # C_new = w*E + (1-w)*(disc*C_old)\n",
        "        w = _sigmoid_np((E - C_hat) / TAU)        # w in (0,1)\n",
        "        C = w * E + (1.0 - w) * (disc * C)\n",
        "\n",
        "        exer_hard = (E > 0.0) & (E >= C_hat)\n",
        "        new_ex = exer_hard & (~exercised)\n",
        "        tau_idx[new_ex] = m\n",
        "        exercised[new_ex] = True\n",
        "\n",
        "\n",
        "    # Pricing stats at t0\n",
        "    C0 = C\n",
        "    price = C0.mean()\n",
        "    stderr = C0.std(ddof=1) / np.sqrt(P)\n",
        "\n",
        "    r2_arr  = np.array(r2_list[::-1])\n",
        "    itm_arr = np.array(itm_list[::-1])\n",
        "    betas_list.reverse()  # now chronological 1..M-1\n",
        "\n",
        "    # === after backward loop, before return ===\n",
        "    #Build near-boundary mask using |payoff - continuation_hat| at the path's τ\n",
        "    near_boundary_mask = np.zeros(P, dtype=bool)\n",
        "    boundary_gap = np.full(P, np.inf, dtype=S.dtype)\n",
        "\n",
        "    for p in range(P):\n",
        "        m = int(tau_idx[p]) if exercised[p] else 0\n",
        "        if m <= 0:\n",
        "            continue\n",
        "        Sm = S[p, m]\n",
        "        E  = payoff_now(Sm, K)\n",
        "        beta_m = betas_by_m[m]\n",
        "        if (beta_m is not None) and (E > 0.0):\n",
        "            x_row = basis_fn(np.array([Sm]))           # shape (1, k)\n",
        "            C_hat_pm = float(x_row @ beta_m)\n",
        "            boundary_gap[p] = abs(float(E - C_hat_pm))\n",
        "\n",
        "    tau0 = max(0.02 * K, 3.0 * TAU)                                     #threshold for \"near boundary\"\n",
        "    near_boundary_mask = (boundary_gap < tau0)\n",
        "\n",
        "    return LSMResult(\n",
        "        price=price,\n",
        "        stderr=stderr,\n",
        "        C_path=C0,\n",
        "        exercised=exercised,\n",
        "        tau_idx=tau_idx,\n",
        "        r2=r2_arr,\n",
        "        itm_counts=itm_arr,\n",
        "        betas=betas_list,\n",
        "        near_boundary_mask=near_boundary_mask,\n",
        "    )\n",
        "\n",
        "\n",
        "def lsm_price(\n",
        "    pack: AMCPaths, K: float,\n",
        "    payoff_now: Callable[[Array, float], Array],\n",
        "    basis_fn: Callable[[Array], Array] = basis_poly3,\n",
        "    *, twin_pack: Optional[AMCPaths] = None,\n",
        ") -> LSMResult:\n",
        "    res_pos = _lsm_single_pack(pack, K, payoff_now, basis_fn)\n",
        "    if twin_pack is None:\n",
        "        return res_pos\n",
        "\n",
        "    res_neg = _lsm_single_pack(twin_pack, K, payoff_now, basis_fn)\n",
        "\n",
        "    C_avg = 0.5 * (res_pos.C_path + res_neg.C_path)\n",
        "    P = C_avg.shape[0]\n",
        "    price = C_avg.mean()\n",
        "    stderr = C_avg.std(ddof=1) / np.sqrt(P)\n",
        "\n",
        "    r2 = np.nanmean(np.vstack([res_pos.r2, res_neg.r2]), axis=0)\n",
        "    itm_counts = 0.5 * (res_pos.itm_counts + res_neg.itm_counts)\n",
        "\n",
        "    if (res_pos.near_boundary_mask is not None) and (res_neg.near_boundary_mask is not None):\n",
        "        nb_mask = (res_pos.near_boundary_mask | res_neg.near_boundary_mask)\n",
        "    else:\n",
        "        nb_mask = res_pos.near_boundary_mask if res_pos.near_boundary_mask is not None else None\n",
        "\n",
        "    return LSMResult(\n",
        "        price=price, stderr=stderr, C_path=C_avg,\n",
        "        exercised=(res_pos.exercised | res_neg.exercised),\n",
        "        tau_idx=np.minimum(res_pos.tau_idx, res_neg.tau_idx),\n",
        "        r2=r2, itm_counts=itm_counts, betas=[res_pos.betas, res_neg.betas],\n",
        "        near_boundary_mask=nb_mask,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf7a4c38-4bad-467e-b93c-7ac3a831aaa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf7a4c38-4bad-467e-b93c-7ac3a831aaa7",
        "outputId": "78c63464-8dbd-41d3-94d0-be9bab81c37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Martingale check: 100.035679 vs 100.000000, rel.err=3.568e-04\n",
            "Antithetic Z consistency (≈0): 0.000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2035818465.py:135: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  C_hat_pm = float(x_row @ beta_m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Single pack] American Put LSM price=6.539392, SE=0.031400\n",
            "[Antithetic avg] American Put LSM price=6.539392, SE=0.010165\n"
          ]
        }
      ],
      "source": [
        "# === Cell 7: quick self-test (small P for notebook) ===\n",
        "S0, r, q, sigma, T = 100.0, 0.03, 0.00, 0.2, 1.0\n",
        "K = 100.0\n",
        "M, P, seed = 50, 50_000, 7\n",
        "amc = simulate_gbm_paths(S0, r, q, sigma, T, M, P, seed=seed, antithetic=True, return_Z=True)\n",
        "lhs = np.exp(-r * T) * amc.S[:, -1].mean()\n",
        "rhs = S0 * np.exp(-q * T)\n",
        "print(f\"Martingale check: {lhs:.6f} vs {rhs:.6f}, rel.err={abs(lhs-rhs)/rhs:.3e}\")\n",
        "\n",
        "pack_pos, pack_neg = prepare_antithetic_paths_for_american(\"GBM\", S0, r, q, T, M, P, sigma=sigma, seed=seed)\n",
        "diff_normals = np.max(np.abs(pack_pos.Z + pack_neg.Z))\n",
        "print(f\"Antithetic Z consistency (≈0): {diff_normals:.3e}\")\n",
        "\n",
        "res = lsm_price(amc, K, payoff_put_now, basis_poly3)\n",
        "print(f\"[Single pack] American Put LSM price={res.price:.6f}, SE={res.stderr:.6f}\")\n",
        "\n",
        "res2 = lsm_price(pack_pos, K, payoff_put_now, basis_poly3, twin_pack=pack_neg)\n",
        "print(f\"[Antithetic avg] American Put LSM price={res2.price:.6f}, SE={res2.stderr:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20d56a04-632f-4637-b4b9-0dfe8d531376",
      "metadata": {
        "id": "20d56a04-632f-4637-b4b9-0dfe8d531376"
      },
      "outputs": [],
      "source": [
        "# === Cell 8: FD Greeks with CRN ===\n",
        "def simulate_gbm_paths_from_Z(\n",
        "    S0: float, r: float, q: float, sigma: float, T: float, *, Z: np.ndarray,\n",
        "    out_log: bool = False, dtype=np.float64,\n",
        ") -> AMCPaths:\n",
        "    P, M = Z.shape\n",
        "    dt = T / M\n",
        "    mu_step  = (r - q - 0.5 * sigma * sigma) * dt\n",
        "    vol_step = sigma * np.sqrt(dt)\n",
        "    log_inc = mu_step + vol_step * Z\n",
        "    np.cumsum(log_inc, axis=1, out=log_inc)\n",
        "    S = np.empty((P, M + 1), dtype=dtype)\n",
        "    S[:, 0] = S0\n",
        "    np.exp(log_inc, out=log_inc)\n",
        "    S[:, 1:] = S0 * log_inc\n",
        "    disc = float(np.exp(-r * dt))\n",
        "    t = np.linspace(0.0, T, M + 1, dtype=dtype)\n",
        "    return AMCPaths(S=S, Z=Z, t=t, disc=disc, dt=dt, r=r, q=q, sigma=sigma, S0=S0)\n",
        "\n",
        "def _scale_pack_S0(pack: AMCPaths, S0_new: float) -> AMCPaths:\n",
        "    S = np.empty_like(pack.S)\n",
        "    S[:, 0] = S0_new\n",
        "    S[:, 1:] = S0_new * (pack.S[:, 1:] / pack.S[:, 0][:, None])\n",
        "    return AMCPaths(S=S, Z=pack.Z, t=pack.t, disc=pack.disc, dt=pack.dt,\n",
        "                    r=pack.r, q=pack.q, sigma=pack.sigma, S0=S0_new)\n",
        "\n",
        "def fd_greeks(\n",
        "    S0: float, K: float, r: float, q: float, sigma: float, T: float,\n",
        "    M: int, P: int, payoff_now, basis_fn,\n",
        "    *, seed: int = 42, h_S: float = 1e-2, h_sig: float = 1e-4\n",
        "):\n",
        "    base_pack = simulate_gbm_paths(S0, r, q, sigma, T, M, P, seed=seed, antithetic=False, return_Z=True)\n",
        "    base_res  = lsm_price(base_pack, K, payoff_now, basis_fn)\n",
        "\n",
        "    pack_Sp = _scale_pack_S0(base_pack, S0 + h_S)\n",
        "    pack_Sm = _scale_pack_S0(base_pack, S0 - h_S)\n",
        "    p_plus  = lsm_price(pack_Sp, K, payoff_now, basis_fn).price\n",
        "    p_minus = lsm_price(pack_Sm, K, payoff_now, basis_fn).price\n",
        "    delta   = (p_plus - p_minus) / (2 * h_S)\n",
        "    gamma   = (p_plus - 2 * base_res.price + p_minus) / (h_S ** 2)\n",
        "\n",
        "    pack_vp = simulate_gbm_paths_from_Z(S0, r, q, sigma + h_sig, T, Z=base_pack.Z)\n",
        "    pack_vm = simulate_gbm_paths_from_Z(S0, r, q, sigma - h_sig, T, Z=base_pack.Z)\n",
        "    p_vp    = lsm_price(pack_vp, K, payoff_now, basis_fn).price\n",
        "    p_vm    = lsm_price(pack_vm, K, payoff_now, basis_fn).price\n",
        "    vega    = (p_vp - p_vm) / (2 * h_sig)\n",
        "\n",
        "    return dict(delta=delta, gamma=gamma, vega=vega), base_res, base_pack\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f49847-cc5c-4839-b04e-bc6b2899ec9d",
      "metadata": {
        "id": "a8f49847-cc5c-4839-b04e-bc6b2899ec9d"
      },
      "outputs": [],
      "source": [
        "# === Cell 9: AAD Frozen Greeks ===\n",
        "def aad_frozen_greeks(pack: AMCPaths, lsm_res: \"LSMResult\", K: float, payoff_now) -> dict:\n",
        "    S = pack.S; Z = pack.Z\n",
        "    P, M1 = S.shape\n",
        "    M = M1 - 1\n",
        "    dt = pack.dt\n",
        "\n",
        "    Wcum = np.cumsum(Z, axis=1) * np.sqrt(dt)  # (P, M)\n",
        "\n",
        "    S0_vec = S[:, 0][:, None]\n",
        "    dS_dS0 = S[:, 1:] / S0_vec\n",
        "\n",
        "    m_idx = np.arange(1, M + 1)[None, :]\n",
        "    t_m = m_idx * dt\n",
        "    dlogS_dsig = -pack.sigma * t_m + Wcum\n",
        "    dS_dsig = S[:, 1:] * dlogS_dsig\n",
        "        # call: σ((S-K)/τ); put: -σ((K-S)/τ)）\n",
        "    if payoff_now is payoff_call_now:\n",
        "        dPhi_dS = _sigmoid_np((S[:, 1:] - K) / TAU).astype(S.dtype)\n",
        "    else:\n",
        "        dPhi_dS = -_sigmoid_np((K - S[:, 1:]) / TAU).astype(S.dtype)\n",
        "\n",
        "\n",
        "    tau = lsm_res.tau_idx.copy()\n",
        "    tau[tau == 0] = M\n",
        "    rows = np.arange(P)\n",
        "\n",
        "    disc_pow = (pack.disc ** tau)\n",
        "\n",
        "    dphi_m  = dPhi_dS[rows, tau - 1]\n",
        "    dS0_m   = dS_dS0[rows, tau - 1]\n",
        "    dsig_m  = dS_dsig[rows, tau - 1]\n",
        "\n",
        "    dPV_dS0  = disc_pow * dphi_m * dS0_m\n",
        "    dPV_dsig = disc_pow * dphi_m * dsig_m\n",
        "\n",
        "    return dict(delta=dPV_dS0.mean(), vega=dPV_dsig.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d3e5e9b-ec80-424f-adc0-d9ca78c0bbea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3e5e9b-ec80-424f-adc0-d9ca78c0bbea",
        "outputId": "6c4f0117-c7d5-4b7c-f7cb-0e8915d246f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/aad_edge_pushing/aad -> OK\n",
            "/content/drive/MyDrive/aad_edge_pushing/aad/core -> OK\n",
            "/content/drive/MyDrive/aad_edge_pushing/aad/ops -> OK\n",
            "✅ Loaded aad from aad_edge_pushing/aad\n",
            "smoke grads: {'x': 7.88905609893065}\n"
          ]
        }
      ],
      "source": [
        "# === Colab: mount drive ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, sys, types, importlib.util, importlib\n",
        "ROOT = \"/content/drive/MyDrive/aad_edge_pushing/aad\"\n",
        "CORE_DIR = os.path.join(ROOT, \"core\")\n",
        "OPS_DIR  = os.path.join(ROOT, \"ops\")\n",
        "\n",
        "for p in [ROOT, CORE_DIR, OPS_DIR]:\n",
        "    print(p, \"->\", \"OK\" if os.path.isdir(p) else \"MISSING\")\n",
        "    if not os.path.isdir(p):\n",
        "        raise FileNotFoundError(f\"Not a directory: {p}\")\n",
        "\n",
        "for name in [\"aad\", \"aad.core\", \"aad.ops\"]:\n",
        "    if name in sys.modules:\n",
        "        del sys.modules[name]\n",
        "\n",
        "aad = types.ModuleType(\"aad\")\n",
        "aad.__path__ = []\n",
        "sys.modules[\"aad\"] = aad\n",
        "\n",
        "aad_core = types.ModuleType(\"aad.core\")\n",
        "aad_core.__path__ = []\n",
        "sys.modules[\"aad.core\"] = aad_core\n",
        "\n",
        "aad_ops = types.ModuleType(\"aad.ops\")\n",
        "aad_ops.__path__ = []\n",
        "sys.modules[\"aad.ops\"] = aad_ops\n",
        "\n",
        "def _load(fullname: str, path: str):\n",
        "    if not os.path.isfile(path):\n",
        "        raise FileNotFoundError(f'{fullname} -> file not found: {path}')\n",
        "    spec = importlib.util.spec_from_file_location(fullname, path)\n",
        "    if spec is None or spec.loader is None:\n",
        "        raise ImportError(f'Cannot load spec for {fullname} from {path}')\n",
        "    mod = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[fullname] = mod\n",
        "    spec.loader.exec_module(mod)\n",
        "    return mod\n",
        "core_files_in_order = [\n",
        "    (\"aad.core.node\",   os.path.join(CORE_DIR, \"node.py\")),\n",
        "    (\"aad.core.tape\",   os.path.join(CORE_DIR, \"tape.py\")),\n",
        "    (\"aad.core.var\",    os.path.join(CORE_DIR, \"var.py\")),\n",
        "    (\"aad.core.engine\", os.path.join(CORE_DIR, \"engine.py\")),\n",
        "    (\"aad.core.seeds\",  os.path.join(CORE_DIR, \"seeds.py\")),\n",
        "    (\"aad.core.taylor_backprop\", os.path.join(CORE_DIR, \"taylor_backprop.py\")),\n",
        "]\n",
        "for fullname, path in core_files_in_order:\n",
        "    _load(fullname, path)\n",
        "\n",
        "ops_files = [\n",
        "    (\"aad.ops.arithmetic\",     os.path.join(OPS_DIR, \"arithmetic.py\")),\n",
        "    (\"aad.ops.transcendental\", os.path.join(OPS_DIR, \"transcendental.py\")),\n",
        "    (\"aad.ops.special\",        os.path.join(OPS_DIR, \"special.py\")),\n",
        "]\n",
        "for fullname, path in ops_files:\n",
        "    _load(fullname, path)\n",
        "\n",
        "for sub in (\"arithmetic\", \"transcendental\", \"special\"):\n",
        "    m = importlib.import_module(f\"aad.ops.{sub}\")\n",
        "    for k, v in m.__dict__.items():\n",
        "        if not k.startswith(\"_\"):\n",
        "            setattr(aad_ops, k, v)\n",
        "\n",
        "print(\"✅ Loaded aad from aad_edge_pushing/aad\")\n",
        "\n",
        "try:\n",
        "    from aad.core.seeds import grads\n",
        "    from aad.core.engine import edge_push_hessian, hvp_for\n",
        "    from aad.core.taylor_backprop import taylor_backpropagate\n",
        "    from aad.ops import exp, log\n",
        "    f = lambda d: exp(d[\"x\"]) + log(d[\"x\"])\n",
        "    g = grads(f, {\"x\": 2.0})\n",
        "    print(\"smoke grads:\", {k: float(v) for k, v in g.items()})\n",
        "except Exception as e:\n",
        "    print(\"❌ smoke failed:\", e)\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b57e2ab-14cc-44ae-b2ae-e5393e10f74f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b57e2ab-14cc-44ae-b2ae-e5393e10f74f",
        "outputId": "cda5b6d2-14b2-4429-c96b-86436cbefd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2035818465.py:135: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  C_hat_pm = float(x_row @ beta_m)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen context ready: P=50000, M=50, payoff=put, early_exercise_ratio=0.851, near-boundary=38900\n"
          ]
        }
      ],
      "source": [
        "# === Cell A: build frozen context from your LSM pricer (fixed) ===\n",
        "import numpy as np\n",
        "\n",
        "# ---- set problem ----\n",
        "S0, r, q, sigma, T = 100.0, 0.03, 0.00, 0.20, 1.0\n",
        "K = 100.0\n",
        "M, P, seed = 50, 50_000, 42\n",
        "is_put = True  # choose call/put\n",
        "\n",
        "# ---- generate base paths & run LSM to get first exercise time tau ----\n",
        "base_pack = simulate_gbm_paths(\n",
        "    S0, r, q, sigma, T, M, P,\n",
        "    seed=seed, antithetic=False, return_Z=True\n",
        ")\n",
        "res_base  = lsm_price(\n",
        "    base_pack, K,\n",
        "    payoff_put_now if is_put else payoff_call_now,\n",
        "    basis_poly3\n",
        ")\n",
        "\n",
        "# ---- freeze Z, Wcum, tau ----\n",
        "Z      = np.asarray(base_pack.Z)                  # (P, M)\n",
        "dt     = float(base_pack.dt)\n",
        "t_grid = np.asarray(base_pack.t)                  # (M+1,)\n",
        "\n",
        "tau = np.asarray(res_base.tau_idx, dtype=np.int32).copy()\n",
        "tau[tau == 0] = M                                 # maturity → step M (no early exercise)\n",
        "\n",
        "# cumulative Brownian (per path)\n",
        "Wcum = np.cumsum(Z, axis=1, dtype=np.float64) * np.sqrt(dt)   # (P, M)\n",
        "\n",
        "# optional near-boundary mask from LSM (may not exist)\n",
        "nbm = getattr(res_base, \"near_boundary_mask\", None)\n",
        "if nbm is not None:\n",
        "    nbm = np.asarray(nbm, dtype=bool)\n",
        "    if nbm.shape[0] != P:\n",
        "        # shape guard\n",
        "        nbm = None\n",
        "\n",
        "# ---- store frozen context (plus base params for numeric baselines) ----\n",
        "frozen_ctx = dict(\n",
        "    Z=Z, Wcum=Wcum, tau=tau, dt=dt, t_grid=t_grid, P=int(P), M=int(M),\n",
        "    payoff=(\"put\" if is_put else \"call\"),\n",
        "    near_boundary_mask=nbm,\n",
        "    # stash base scalars for FD / off-tape math\n",
        "    S0_base=float(S0), sigma_base=float(sigma), r_base=float(r), K_base=float(K),\n",
        ")\n",
        "\n",
        "# ---- diagnostics ----\n",
        "early_ratio = float((tau < M).mean())            # truly early exercised ratio\n",
        "nb_count    = (int(nbm.sum()) if nbm is not None else \"N/A\")\n",
        "\n",
        "print(\n",
        "    \"Frozen context ready:\",\n",
        "    f\"P={P}, M={M}, payoff={frozen_ctx['payoff']}, \"\n",
        "    f\"early_exercise_ratio={early_ratio:.3f}, near-boundary={nb_count}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "524703ae-a43a-4889-9406-059cc72f8382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "524703ae-a43a-4889-9406-059cc72f8382",
        "outputId": "b6977fe5-b86e-46e5-a9ab-837079088bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frozen-LSM grads (AAD): {'S0': 0.5791020635160776, 'sigma': 39.963220156696394, 'r': -45.14516432961233, 'T': 0.0, 'K': 0.48905756500802056}\n",
            "Active-set size: 38900 / 50000\n"
          ]
        }
      ],
      "source": [
        "# === Cell B: Frozen-LSM scalar price with AAD (grads + EP Hessian, smoothed) ===\n",
        "import numpy as np, pandas as pd\n",
        "from aad.ops import exp as aexp, log as alog\n",
        "from aad.core.engine import edge_push_hessian\n",
        "from aad.core.seeds import grads\n",
        "\n",
        "# ---------------- Shared smoothing (align with forward LSM) ----------------\n",
        "TAU = 0.10\n",
        "\n",
        "def _softplus_np(x):\n",
        "    return np.where(x > 20, x, np.log1p(np.exp(x)))\n",
        "\n",
        "def smooth_max_np(a, b, tau=TAU):\n",
        "    return b + tau * _softplus_np((a - b) / tau)\n",
        "\n",
        "def softplus_ad(x):\n",
        "    return alog(1.0 + aexp(x))\n",
        "\n",
        "def smooth_max_ad(a, b, tau=TAU):\n",
        "    return b + tau * softplus_ad((a - b) / tau)\n",
        "\n",
        "def _to_float(x):\n",
        "    try:\n",
        "        return float(x)\n",
        "    except Exception:\n",
        "        for attr in (\"x\", \"val\", \"value\", \"data\"):\n",
        "            if hasattr(x, attr):\n",
        "                try:\n",
        "                    return float(getattr(x, attr))\n",
        "                except Exception:\n",
        "                    pass\n",
        "        return float(np.array(x, dtype=float))\n",
        "\n",
        "def _aad_mean(x):\n",
        "    try:\n",
        "        n = int(np.size(x))\n",
        "        if n <= 1:\n",
        "            return x.item() if hasattr(x, \"item\") else x\n",
        "        total = None\n",
        "        for xi in np.ravel(x):\n",
        "            total = xi if total is None else (total + xi)\n",
        "        return total * (1.0 / n)\n",
        "    except Exception:\n",
        "        return x\n",
        "\n",
        "def _aad_reduce_scalar(x):\n",
        "    shp = getattr(x, \"shape\", None)\n",
        "    if shp is not None and shp != ():\n",
        "        return _aad_mean(x)\n",
        "    return x\n",
        "\n",
        "# ---------------- frozen LSM：Full sample（For sanity check） ----------------\n",
        "def frozen_lsm_price_aad(params):\n",
        "    \"\"\"Scalar frozen-LSM price (τ/Z frozen), AAD ops + smooth payoff/decision.\"\"\"\n",
        "    S0, sigma, r, T, K = params[\"S0\"], params[\"sigma\"], params[\"r\"], params[\"T\"], params[\"K\"]\n",
        "    Wcum, tau, dt, tgrid = (frozen_ctx[k] for k in [\"Wcum\",\"tau\",\"dt\",\"t_grid\"])\n",
        "    P, is_put = frozen_ctx[\"P\"], (frozen_ctx[\"payoff\"] == \"put\")\n",
        "\n",
        "    total = 0.0\n",
        "    for p in range(P):\n",
        "        m = int(tau[p])\n",
        "        t_m = tgrid[m]\n",
        "        W_t = Wcum[p, m-1] if m >= 1 else 0.0\n",
        "        mu  = r - 0.5 * sigma * sigma\n",
        "        Sm  = S0 * aexp(mu * t_m + sigma * W_t)\n",
        "        if is_put:\n",
        "            payoff = smooth_max_ad(K, Sm, TAU)   # max(K-Sm,0)\n",
        "        else:\n",
        "            payoff = smooth_max_ad(Sm, K, TAU)   # max(Sm-K,0)\n",
        "        total += aexp(-r * (m * dt)) * payoff\n",
        "    return total / P\n",
        "\n",
        "# ---------------- Frozrn LSM：Per batch ----------------\n",
        "def frozen_lsm_price_aad_batch(params, batch_idx, index_subset=None):\n",
        "    S0, sigma, r, K = params[\"S0\"], params[\"sigma\"], params[\"r\"], params[\"K\"]\n",
        "    tau_all = frozen_ctx[\"tau\"][batch_idx].astype(int)\n",
        "    dt, tgrid, Wcum = frozen_ctx[\"dt\"], frozen_ctx[\"t_grid\"], frozen_ctx[\"Wcum\"]\n",
        "    is_put = (frozen_ctx[\"payoff\"] == \"put\")\n",
        "\n",
        "    # numeric copies for off-tape math\n",
        "    S0_, sig_, r_, K_ = (frozen_ctx.get(k, _to_float(v))\n",
        "                         for k, v in zip([\"S0_base\",\"sigma_base\",\"r_base\",\"K_base\"],\n",
        "                                         [S0, sigma, r, K]))\n",
        "\n",
        "    # active indices（进入 AAD）\n",
        "    if index_subset is None:\n",
        "        active = np.arange(len(batch_idx))\n",
        "    else:\n",
        "        mask = np.isin(batch_idx, index_subset)\n",
        "        active = np.nonzero(mask)[0]\n",
        "\n",
        "    B = len(batch_idx)\n",
        "    total = 0.0\n",
        "\n",
        "    if index_subset is None:\n",
        "        active = np.arange(B, dtype=int)\n",
        "    else:\n",
        "        mask = np.isin(batch_idx, index_subset)   # shape = (B,)\n",
        "        active = np.nonzero(mask)[0]\n",
        "\n",
        "    t_m_all = tgrid[tau_all]\n",
        "    W_t_all = np.zeros(B)\n",
        "    ge1 = tau_all >= 1\n",
        "    if np.any(ge1):\n",
        "        W_t_all[ge1] = Wcum[batch_idx[ge1], tau_all[ge1]-1]\n",
        "    m_dt_all = tau_all * dt\n",
        "\n",
        "    # --- off-tape ---\n",
        "    if active.size < B:\n",
        "        ia = np.setdiff1d(np.arange(B), active, assume_unique=True)\n",
        "        tm, wt, mdt = t_m_all[ia], W_t_all[ia], m_dt_all[ia]\n",
        "        mu = r_ - 0.5 * sig_ * sig_\n",
        "        Sm = S0_ * np.exp(mu * tm + sig_ * wt)\n",
        "        if is_put:\n",
        "            payoff = smooth_max_np(K_, Sm, TAU)\n",
        "        else:\n",
        "            payoff = smooth_max_np(Sm, K_, TAU)\n",
        "        total += np.mean(np.exp(-r_ * mdt) * payoff)\n",
        "\n",
        "    # --- on-tape ---\n",
        "    if active.size > 0:\n",
        "        tm, wt, mdt = t_m_all[active], W_t_all[active], m_dt_all[active]\n",
        "        acc = None\n",
        "        for k in range(len(tm)):\n",
        "            mu_k = r - 0.5 * sigma * sigma\n",
        "            Sm_k = S0 * aexp(mu_k * tm[k] + sigma * wt[k])\n",
        "            if is_put:\n",
        "                pay_k = smooth_max_ad(K, Sm_k, TAU)\n",
        "            else:\n",
        "                pay_k = smooth_max_ad(Sm_k, K, TAU)\n",
        "            pv_k  = aexp(-r * mdt[k]) * pay_k\n",
        "            acc = pv_k if acc is None else (acc + pv_k)\n",
        "        total += acc * (1.0 / len(tm))\n",
        "    return _aad_reduce_scalar(total)\n",
        "\n",
        "# ---------------- EP Hessian(3x3) ----------------\n",
        "def _ep_partial_block(H_full, inputs, keys=(\"S0\",\"sigma\",\"r\")):\n",
        "    in_keys = list(inputs.keys())\n",
        "    idx = [in_keys.index(k) for k in keys]\n",
        "    H = np.asarray(H_full, float)\n",
        "    H = 0.5 * (H + H.T)\n",
        "    return H[np.ix_(idx, idx)]\n",
        "\n",
        "def edge_push_hessian_batched(inputs, batch_size=256, subset_idx=None):\n",
        "    \"\"\"\n",
        "    按 τ 分桶之后跑 EP。\n",
        "    - inputs: {\"S0\":..., \"sigma\":..., \"r\":..., \"K\":...}\n",
        "    - subset_idx: 如果你只想跑 near-boundary 那些路径，就传它；否则就是全量\n",
        "    \"\"\"\n",
        "    tau_all = np.asarray(frozen_ctx[\"tau\"], dtype=int)\n",
        "    P = tau_all.shape[0]\n",
        "\n",
        "    if subset_idx is not None:\n",
        "        mask = np.isin(np.arange(P), subset_idx)\n",
        "        tau_used = tau_all[mask]\n",
        "        idx_used = np.arange(P)[mask]\n",
        "    else:\n",
        "        tau_used = tau_all\n",
        "        idx_used = np.arange(P)\n",
        "    buckets = {}\n",
        "    for path_id, tstop in zip(idx_used, tau_used):\n",
        "        buckets.setdefault(int(tstop), []).append(int(path_id))\n",
        "\n",
        "    H_acc, n_eff = None, 0\n",
        "\n",
        "    for tstop, path_ids in sorted(buckets.items(), key=lambda kv: kv[0]):\n",
        "        path_ids = np.asarray(path_ids, dtype=int)\n",
        "\n",
        "        for s in range(0, len(path_ids), batch_size):\n",
        "            batch_ids = path_ids[s:s+batch_size]\n",
        "\n",
        "            f_batch = (lambda idx=batch_ids:\n",
        "                       (lambda prm: frozen_lsm_price_aad_batch(prm, idx, index_subset=idx)))(batch_ids)\n",
        "\n",
        "            H_full = edge_push_hessian(f_batch, inputs, sparse=False)\n",
        "            H_blk  = _ep_partial_block(H_full, inputs, (\"S0\",\"sigma\",\"r\"))\n",
        "\n",
        "            H_acc = H_blk if H_acc is None else (H_acc + H_blk)\n",
        "            n_eff += 1\n",
        "\n",
        "    if n_eff == 0:\n",
        "        raise RuntimeError(\"No buckets produced EP runs.\")\n",
        "    return H_acc / n_eff\n",
        "\n",
        "\n",
        "inputs = {\"S0\": S0, \"sigma\": sigma, \"r\": r, \"T\": T, \"K\": K}\n",
        "g = grads(frozen_lsm_price_aad, inputs)\n",
        "print(\"Frozen-LSM grads (AAD):\", {k: float(v) for k, v in g.items()})\n",
        "\n",
        "nbm = frozen_ctx.get(\"near_boundary_mask\", None)\n",
        "subset_idx = np.nonzero(nbm)[0] if (nbm is not None and nbm.any()) else None\n",
        "nb_count = 0 if subset_idx is None else subset_idx.size\n",
        "print(f\"Active-set size: {nb_count} / {frozen_ctx['P']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell C: AAD (EP) vs Forward Bumping (CRN) — Greeks & Timing (smoothed) ===\n",
        "import numpy as np, pandas as pd, time\n",
        "from aad.core.engine import edge_push_hessian\n",
        "from aad.core.seeds import grads\n",
        "from aad.ops import exp as aexp\n",
        "\n",
        "BATCH       = 1000\n",
        "MAX_BATCHES = 40\n",
        "CAP_ACTIVE  = 500\n",
        "FD_STEP_1   = 1e-4\n",
        "FD_STEP_2   = 1e-3\n",
        "np.set_printoptions(suppress=True)\n",
        "print(f\"[Run] batch={BATCH}, max_batches={MAX_BATCHES}, cap_active={CAP_ACTIVE}, fd1={FD_STEP_1}, fd2={FD_STEP_2}\")\n",
        "\n",
        "P      = int(frozen_ctx[\"P\"])\n",
        "dt     = float(frozen_ctx[\"dt\"])\n",
        "tgrid  = frozen_ctx[\"t_grid\"]\n",
        "tau    = frozen_ctx[\"tau\"].astype(int)\n",
        "Wcum   = frozen_ctx[\"Wcum\"]\n",
        "is_put = (frozen_ctx[\"payoff\"] == \"put\")\n",
        "\n",
        "m_idx  = tau\n",
        "t_m    = tgrid[m_idx]\n",
        "W_t    = np.where(m_idx > 0, Wcum[np.arange(P), m_idx - 1], 0.0)\n",
        "m_dt   = m_idx * dt\n",
        "\n",
        "S0, sigma, r, T, K = float(frozen_ctx[\"S0_base\"]), float(frozen_ctx[\"sigma_base\"]), float(frozen_ctx[\"r_base\"]), float(frozen_ctx.get(\"T_base\", 1.0)), float(frozen_ctx[\"K_base\"])\n",
        "names_3 = [\"S0\",\"sigma\",\"r\"]\n",
        "\n",
        "def make_batches(P, batch_size, max_batches=None, cap=None, seed=123):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    n_full = int(np.ceil(P / batch_size))\n",
        "    batches = []\n",
        "    for bi in range(n_full):\n",
        "        if max_batches is not None and len(batches) >= max_batches:\n",
        "            break\n",
        "        s, e = bi * batch_size, min(P, (bi + 1) * batch_size)\n",
        "        idx = np.arange(s, e, dtype=int)\n",
        "        if cap is not None and len(idx) > cap:\n",
        "            idx = np.sort(rng.choice(idx, size=cap, replace=False))\n",
        "        batches.append(idx)\n",
        "    if not batches:\n",
        "        raise RuntimeError(\"No batches; check knobs.\")\n",
        "    return batches\n",
        "\n",
        "batches = make_batches(P, BATCH, MAX_BATCHES, CAP_ACTIVE, seed=123)\n",
        "print(f\"[Batches] {len(batches)} × ~{(CAP_ACTIVE or BATCH)} ≈ {len(batches)*(CAP_ACTIVE or BATCH)} paths total\")\n",
        "\n",
        "def price_numeric_on_indices(S0, sigma, r, T, K, indices):\n",
        "    tm, wt, mdt = t_m[indices], W_t[indices], m_dt[indices]\n",
        "    mu  = r - 0.5 * sigma * sigma\n",
        "    Sm  = S0 * np.exp(mu * tm + sigma * wt)\n",
        "    if is_put:\n",
        "        payoff = smooth_max_np(K, Sm, TAU)\n",
        "    else:\n",
        "        payoff = smooth_max_np(Sm, K, TAU)\n",
        "    return float(np.mean(np.exp(-r * mdt) * payoff))\n",
        "\n",
        "def price_aad_on_indices(d, indices):\n",
        "    S0, sigma, r, T, K = d[\"S0\"], d[\"sigma\"], d[\"r\"], d[\"T\"], d[\"K\"]\n",
        "    total = 0.0\n",
        "    for p in indices:\n",
        "        tm, wt, mdt = float(t_m[p]), float(W_t[p]), float(m_dt[p])\n",
        "        mu  = r - 0.5 * sigma * sigma\n",
        "        Sm  = S0 * aexp(mu * tm + sigma * wt)\n",
        "        if is_put:\n",
        "            payoff = smooth_max_ad(K, Sm, TAU)\n",
        "        else:\n",
        "            payoff = smooth_max_ad(Sm, K, TAU)\n",
        "        total += aexp(-r * mdt) * payoff\n",
        "    return total / float(len(indices))\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "g_ep_acc = np.zeros(3, float)\n",
        "for idx in batches:\n",
        "    inputs3 = {\"S0\": S0, \"sigma\": sigma, \"r\": r}\n",
        "    f3 = lambda prm3: price_aad_on_indices(\n",
        "        {\"S0\": prm3[\"S0\"], \"sigma\": prm3[\"sigma\"], \"r\": prm3[\"r\"], \"T\": float(T), \"K\": float(K)},\n",
        "        idx\n",
        "    )\n",
        "    g3 = grads(f3, inputs3)\n",
        "    g_ep_acc += np.array([float(g3[\"S0\"]), float(g3[\"sigma\"]), float(g3[\"r\"])])\n",
        "g1_ep = g_ep_acc / len(batches)\n",
        "t_g1_ep = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "from aad.core.tape import global_tape\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "H_ep_acc = np.zeros((3, 3), float)\n",
        "for idx in batches:\n",
        "    global_tape.reset()\n",
        "\n",
        "    inputs3 = {\"S0\": S0, \"sigma\": sigma, \"r\": r}\n",
        "\n",
        "    def f3(prm3, idx=idx):\n",
        "        return price_aad_on_indices(\n",
        "            {\n",
        "                \"S0\": prm3[\"S0\"],\n",
        "                \"sigma\": prm3[\"sigma\"],\n",
        "                \"r\": prm3[\"r\"],\n",
        "                \"T\": float(T),\n",
        "                \"K\": float(K),\n",
        "            },\n",
        "            idx,\n",
        "        )\n",
        "\n",
        "    H_full = edge_push_hessian(f3, inputs3, sparse=False)\n",
        "    H_full = np.array(H_full, float)\n",
        "    H_full = 0.5 * (H_full + H_full.T)\n",
        "    H_ep_acc += H_full\n",
        "\n",
        "H2_ep = H_ep_acc / len(batches)\n",
        "t_h2_ep = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "\n",
        "def grad_fd_on_indices(x0, idx, h):\n",
        "    f = lambda x: price_numeric_on_indices(x[0], x[1], x[2], T, K, idx)\n",
        "    g = np.zeros(3, float)\n",
        "    for i in range(3):\n",
        "        xp, xm = x0.copy(), x0.copy()\n",
        "        xp[i] += h; xm[i] -= h\n",
        "        g[i] = (f(xp) - f(xm)) / (2*h)\n",
        "    return g\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "x0 = np.array([S0, sigma, r], float)\n",
        "g_fd_acc = np.zeros(3, float)\n",
        "for idx in batches:\n",
        "    g_fd_acc += grad_fd_on_indices(x0, idx, FD_STEP_1)\n",
        "g1_fd = g_fd_acc / len(batches)\n",
        "t_g1_fd = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "def hess_fd_on_indices(x0, idx, h):\n",
        "    f = lambda x: price_numeric_on_indices(x[0], x[1], x[2], T, K, idx)\n",
        "    H = np.zeros((3,3), float)\n",
        "    f00 = f(x0)\n",
        "    # diag\n",
        "    for i in range(3):\n",
        "        xp, xm = x0.copy(), x0.copy()\n",
        "        xp[i] += h; xm[i] -= h\n",
        "        H[i,i] = (f(xp) - 2*f00 + f(xm)) / (h*h)\n",
        "    # off-diag\n",
        "    for i in range(3):\n",
        "        for j in range(i+1,3):\n",
        "            xpp, xpm, xmp, xmm = [x0.copy() for _ in range(4)]\n",
        "            xpp[i]+=h; xpp[j]+=h\n",
        "            xpm[i]+=h; xpm[j]-=h\n",
        "            xmp[i]-=h; xmm[j]-=h\n",
        "            xmp[j]+=h; xmm[i]-=h\n",
        "            H[i,j] = H[j,i] = (f(xpp)-f(xpm)-f(xmp)+f(xmm))/(4*h*h)\n",
        "    return H\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "H_fd_acc = np.zeros((3,3), float)\n",
        "for idx in batches:\n",
        "    H_fd_acc += hess_fd_on_indices(x0, idx, FD_STEP_2)\n",
        "H2_fd = H_fd_acc / len(batches)\n",
        "t_h2_fd = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "df_g_ep = pd.Series(g1_ep, index=names_3, name=\"AAD-EP\")\n",
        "df_g_fd = pd.Series(g1_fd, index=names_3, name=\"FD\")\n",
        "df_H_ep = pd.DataFrame(H2_ep, index=names_3, columns=names_3)\n",
        "df_H_fd = pd.DataFrame(H2_fd, index=names_3, columns=names_3)\n",
        "df_H_diff = df_H_ep - df_H_fd\n",
        "\n",
        "print(\"\\n--- Timing (ms) ---\")\n",
        "print(f\"AAD 1st (grads): {t_g1_ep:.1f}   |   FD 1st: {t_g1_fd:.1f}\")\n",
        "print(f\"AAD 2nd (EP):    {t_h2_ep:.1f}   |   FD 2nd:  {t_h2_fd:.1f}\")\n",
        "\n",
        "print(\"\\n--- First-order Greeks (batch-avg) ---\")\n",
        "print(pd.concat([df_g_ep, df_g_fd], axis=1))\n",
        "\n",
        "print(\"\\n--- Second-order Hessian 3×3 (AAD-EP) ---\")\n",
        "print(df_H_ep.round(6))\n",
        "print(\"\\n--- Second-order Hessian 3×3 (FD) ---\")\n",
        "print(df_H_fd.round(6))\n",
        "print(\"\\n--- Diff (AAD-EP - FD) ---\")\n",
        "print(df_H_diff.round(6))\n",
        "print(f\"\\nmax|diff(H)| = {np.abs(df_H_diff.values).max():.3e}\")\n",
        "\n",
        "Gamma = H2_ep[0,0]; Vanna = H2_ep[0,1]; Volga = H2_ep[1,1]\n",
        "print(f\"\\n[Key Greeks AAD]  Delta={g1_ep[0]:.4e}, Vega={g1_ep[1]:.4e}, Rho={g1_ep[2]:.4e}\")\n",
        "print(f\"[Key Greeks AAD]  Gamma={Gamma:.4e}, Vanna={Vanna:.4e}, Volga={Volga:.4e}\")\n",
        "print(f\"[Key Greeks  FD]  Delta={g1_fd[0]:.4e}, Vega={g1_fd[1]:.4e}, Rho={g1_fd[2]:.4e}\")\n",
        "print(f\"[Key Greeks  FD]  Gamma={H2_fd[0,0]:.4e}, Vanna={H2_fd[0,1]:.4e}, Volga={H2_fd[1,1]:.4e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLRa5BrGBcxF",
        "outputId": "d8068a24-cf9e-4ce3-9877-85e918c936cf"
      },
      "id": "JLRa5BrGBcxF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Run] batch=1000, max_batches=40, cap_active=500, fd1=0.0001, fd2=0.001\n",
            "[Batches] 40 × ~500 ≈ 20000 paths total\n",
            "\n",
            "--- Timing (ms) ---\n",
            "AAD 1st (grads): 43562.0   |   FD 1st: 17.2\n",
            "AAD 2nd (EP):    538931.6   |   FD 2nd:  51.6\n",
            "\n",
            "--- First-order Greeks (batch-avg) ---\n",
            "          AAD-EP         FD\n",
            "S0      0.581865   0.581865\n",
            "sigma  40.115347  40.115347\n",
            "r     -44.968157 -44.968158\n",
            "\n",
            "--- Second-order Hessian 3×3 (AAD-EP) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Second-order Hessian 3×3 (FD) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160795    0.961112\n",
            "sigma  0.160795  -8.269513  -24.030756\n",
            "r      0.961112 -24.030756  138.539383\n",
            "\n",
            "--- Diff (AAD-EP - FD) ---\n",
            "             S0     sigma         r\n",
            "S0     0.000000 -0.000002  0.000353\n",
            "sigma -0.000002 -0.000008 -0.005276\n",
            "r      0.000353 -0.005276  0.023477\n",
            "\n",
            "max|diff(H)| = 2.348e-02\n",
            "\n",
            "[Key Greeks AAD]  Delta=5.8187e-01, Vega=4.0115e+01, Rho=-4.4968e+01\n",
            "[Key Greeks AAD]  Gamma=9.6146e-03, Vanna=1.6079e-01, Volga=-8.2695e+00\n",
            "[Key Greeks  FD]  Delta=5.8187e-01, Vega=4.0115e+01, Rho=-4.4968e+01\n",
            "[Key Greeks  FD]  Gamma=9.6146e-03, Vanna=1.6080e-01, Volga=-8.2695e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell D: Taylor-backprop Hessian (batched, clean) ===\n",
        "import time, numpy as np, pandas as pd\n",
        "from aad.core.taylor_backprop import taylor_backpropagate\n",
        "from aad.core.tape import global_tape\n",
        "from aad.core.var import ADVar\n",
        "\n",
        "KEYS_3 = [\"S0\", \"sigma\", \"r\"]\n",
        "\n",
        "def _to_scalar(x):\n",
        "    if isinstance(x, ADVar):\n",
        "        return float(x.val)\n",
        "    return float(x)\n",
        "\n",
        "def _taylor_hessian_once(f_callable, inputs3):\n",
        "    global_tape.reset()\n",
        "    prm_ad = {\n",
        "        k: ADVar(_to_scalar(inputs3[k]), requires_grad=True, name=k)\n",
        "        for k in KEYS_3\n",
        "    }\n",
        "    y = f_callable(prm_ad)\n",
        "    if not isinstance(y, ADVar):\n",
        "        raise TypeError(f\"f_callable must return ADVar, got {type(y)}\")\n",
        "\n",
        "    order = [prm_ad[k] for k in KEYS_3]\n",
        "    g, H = taylor_backpropagate(order)\n",
        "\n",
        "    return 0.5 * (H + H.T)\n",
        "\n",
        "def taylor_hessian_batched(inputs3, batches):\n",
        "    H_acc = np.zeros((3, 3), float)\n",
        "    n_eff = 0\n",
        "\n",
        "    for idx in batches:\n",
        "        def f3(prm3, idx=idx):\n",
        "            return price_aad_on_indices(\n",
        "                {\n",
        "                    \"S0\": prm3[\"S0\"],\n",
        "                    \"sigma\": prm3[\"sigma\"],\n",
        "                    \"r\": prm3[\"r\"],\n",
        "                    \"T\": float(T),\n",
        "                    \"K\": float(K),\n",
        "                },\n",
        "                idx,\n",
        "            )\n",
        "\n",
        "        H_acc += _taylor_hessian_once(f3, inputs3)\n",
        "        n_eff += 1\n",
        "\n",
        "    if n_eff == 0:\n",
        "        raise RuntimeError(\"No batches for Taylor.\")\n",
        "\n",
        "    return H_acc / n_eff\n",
        "\n",
        "inputs_clean = {\n",
        "    \"S0\": float(S0.val) if isinstance(S0, ADVar) else float(S0),\n",
        "    \"sigma\": float(sigma.val) if isinstance(sigma, ADVar) else float(sigma),\n",
        "    \"r\": float(r.val) if isinstance(r, ADVar) else float(r),\n",
        "}\n",
        "\n",
        "t0 = time.perf_counter()\n",
        "H2_taylor = taylor_hessian_batched(inputs_clean, batches)\n",
        "t_h2_taylor = (time.perf_counter() - t0) * 1e3\n",
        "\n",
        "names_3 = [\"S0\", \"sigma\", \"r\"]\n",
        "print(\"\\n--- Second-order Hessian 3×3 (Taylor) ---\")\n",
        "print(pd.DataFrame(H2_taylor, index=names_3, columns=names_3).round(6))\n",
        "print(f\"\\n[Timing] Taylor 2nd (batched): {t_h2_taylor:.1f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUnCHRIvs_0N",
        "outputId": "552a0e63-5984-4250-eadc-d432b2753003"
      },
      "id": "SUnCHRIvs_0N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Second-order Hessian 3×3 (Taylor) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "[Timing] Taylor 2nd (batched): 25307.0 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell E: EP vs FD vs Taylor — speed & accuracy comparison ===\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def frob(A):\n",
        "    A = np.asarray(A, float)\n",
        "    return float(np.sqrt(np.sum(A*A)))\n",
        "\n",
        "print(\"\\n================ SPEED (this run) ================\")\n",
        "print(f\"EP (Hessian)   : {t_h2_ep:.1f} ms\")\n",
        "print(f\"Taylor (Hess)  : {t_h2_taylor:.1f} ms\")\n",
        "print(f\"FD (Hessian)   : {t_h2_fd:.1f} ms\")\n",
        "print(f\"×(Taylor vs EP): ×{(t_h2_taylor / max(t_h2_ep,1e-12)):.2f}\")\n",
        "print(f\"×(FD vs EP)    : ×{(t_h2_fd / max(t_h2_ep,1e-12)):.2f}\")\n",
        "\n",
        "den = max(frob(H2_ep), 1e-12)\n",
        "relerr_T = frob(H2_taylor - H2_ep) / den\n",
        "relerr_F = frob(H2_fd     - H2_ep) / den\n",
        "\n",
        "print(\"\\n================ ACCURACY (relative to EP) ================\")\n",
        "print(f\"relerr(Taylor, EP) = {relerr_T:.3e}\")\n",
        "print(f\"relerr(FD,    EP) = {relerr_F:.3e}\")\n",
        "\n",
        "df_H_ep     = pd.DataFrame(H2_ep,     index=names_3, columns=names_3)\n",
        "df_H_taylor = pd.DataFrame(H2_taylor, index=names_3, columns=names_3)\n",
        "df_H_fd     = pd.DataFrame(H2_fd,     index=names_3, columns=names_3)\n",
        "\n",
        "print(\"\\n--- Hessian (Edge-Pushing) ---\")\n",
        "print(df_H_ep.round(6))\n",
        "print(\"\\n--- Hessian (Taylor) ---\")\n",
        "print(df_H_taylor.round(6))\n",
        "print(\"\\n--- Hessian (FD) ---\")\n",
        "print(df_H_fd.round(6))\n",
        "\n",
        "print(\"\\n--- Diff: Taylor - EP ---\")\n",
        "print((df_H_taylor - df_H_ep).round(6))\n",
        "print(\"\\n--- Diff: FD - EP ---\")\n",
        "print((df_H_fd - df_H_ep).round(6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcE_pE_VGaPq",
        "outputId": "7246db29-50cf-4d80-fa8f-b75303497ef6"
      },
      "id": "rcE_pE_VGaPq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ SPEED (this run) ================\n",
            "EP (Hessian)   : 538931.6 ms\n",
            "Taylor (Hess)  : 25307.0 ms\n",
            "FD (Hessian)   : 51.6 ms\n",
            "×(Taylor vs EP): ×0.05\n",
            "×(FD vs EP)    : ×0.00\n",
            "\n",
            "================ ACCURACY (relative to EP) ================\n",
            "relerr(Taylor, EP) = 2.645e-15\n",
            "relerr(FD,    EP) = 1.724e-04\n",
            "\n",
            "--- Hessian (Edge-Pushing) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Hessian (Taylor) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Hessian (FD) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160795    0.961112\n",
            "sigma  0.160795  -8.269513  -24.030756\n",
            "r      0.961112 -24.030756  138.539383\n",
            "\n",
            "--- Diff: Taylor - EP ---\n",
            "        S0  sigma    r\n",
            "S0     0.0   -0.0  0.0\n",
            "sigma -0.0    0.0 -0.0\n",
            "r      0.0   -0.0  0.0\n",
            "\n",
            "--- Diff: FD - EP ---\n",
            "             S0     sigma         r\n",
            "S0    -0.000000  0.000002 -0.000353\n",
            "sigma  0.000002  0.000008  0.005276\n",
            "r     -0.000353  0.005276 -0.023477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell E: EP vs FD vs Taylor — speed & accuracy comparison ===\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "def frob(A):\n",
        "    A = np.asarray(A, float)\n",
        "    return float(np.sqrt(np.sum(A*A)))\n",
        "\n",
        "print(\"\\n================ SPEED (this run) ================\")\n",
        "print(f\"EP (Hessian)   : {t_h2_ep:.1f} ms\")\n",
        "print(f\"Taylor (Hess)  : {t_h2_taylor:.1f} ms\")\n",
        "print(f\"FD (Hessian)   : {t_h2_fd:.1f} ms\")\n",
        "print(f\"×(Taylor vs EP): ×{(t_h2_taylor / max(t_h2_ep,1e-12)):.2f}\")\n",
        "print(f\"×(FD vs EP)    : ×{(t_h2_fd / max(t_h2_ep,1e-12)):.2f}\")\n",
        "\n",
        "den = max(frob(H2_ep), 1e-12)\n",
        "relerr_T = frob(H2_taylor - H2_ep) / den\n",
        "relerr_F = frob(H2_fd     - H2_ep) / den\n",
        "\n",
        "print(\"\\n================ ACCURACY (relative to EP) ================\")\n",
        "print(f\"relerr(Taylor, EP) = {relerr_T:.3e}\")\n",
        "print(f\"relerr(FD,    EP) = {relerr_F:.3e}\")\n",
        "\n",
        "df_H_ep     = pd.DataFrame(H2_ep,     index=names_3, columns=names_3)\n",
        "df_H_taylor = pd.DataFrame(H2_taylor, index=names_3, columns=names_3)\n",
        "df_H_fd     = pd.DataFrame(H2_fd,     index=names_3, columns=names_3)\n",
        "\n",
        "print(\"\\n--- Hessian (Edge-Pushing) ---\")\n",
        "print(df_H_ep.round(6))\n",
        "print(\"\\n--- Hessian (Taylor) ---\")\n",
        "print(df_H_taylor.round(6))\n",
        "print(\"\\n--- Hessian (FD) ---\")\n",
        "print(df_H_fd.round(6))\n",
        "\n",
        "print(\"\\n--- Diff: Taylor - EP ---\")\n",
        "print((df_H_taylor - df_H_ep).round(6))\n",
        "print(\"\\n--- Diff: FD - EP ---\")\n",
        "print((df_H_fd - df_H_ep).round(6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0K2BjAWdGek5",
        "outputId": "348553fb-7d9a-4704-9b17-4b80e90965c2"
      },
      "id": "0K2BjAWdGek5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ SPEED (this run) ================\n",
            "EP (Hessian)   : 538931.6 ms\n",
            "Taylor (Hess)  : 25307.0 ms\n",
            "FD (Hessian)   : 51.6 ms\n",
            "×(Taylor vs EP): ×0.05\n",
            "×(FD vs EP)    : ×0.00\n",
            "\n",
            "================ ACCURACY (relative to EP) ================\n",
            "relerr(Taylor, EP) = 2.645e-15\n",
            "relerr(FD,    EP) = 1.724e-04\n",
            "\n",
            "--- Hessian (Edge-Pushing) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Hessian (Taylor) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Hessian (FD) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160795    0.961112\n",
            "sigma  0.160795  -8.269513  -24.030756\n",
            "r      0.961112 -24.030756  138.539383\n",
            "\n",
            "--- Diff: Taylor - EP ---\n",
            "        S0  sigma    r\n",
            "S0     0.0   -0.0  0.0\n",
            "sigma -0.0    0.0 -0.0\n",
            "r      0.0   -0.0  0.0\n",
            "\n",
            "--- Diff: FD - EP ---\n",
            "             S0     sigma         r\n",
            "S0    -0.000000  0.000002 -0.000353\n",
            "sigma  0.000002  0.000008  0.005276\n",
            "r     -0.000353  0.005276 -0.023477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Final consolidated output: EP / FD / Taylor full comparison ===\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "names_3 = [\"S0\", \"sigma\", \"r\"]\n",
        "\n",
        "# --- Run config (echo) ---\n",
        "print(\"\\n[Run] batch={}, max_batches={}, cap_active={}, fd1={}, fd2={}\".format(\n",
        "    BATCH,\n",
        "    MAX_BATCHES,\n",
        "    CAP_ACTIVE,\n",
        "    FD_STEP_1,\n",
        "    FD_STEP_2,\n",
        "))\n",
        "print(\"[Batches] {} × ~{} ≈ {} paths total\".format(\n",
        "    len(batches),\n",
        "    (CAP_ACTIVE or BATCH),\n",
        "    len(batches) * (CAP_ACTIVE or BATCH),\n",
        "))\n",
        "\n",
        "# --- Problem setup (frozen) ---\n",
        "print(\"\\n=== Problem setup (frozen) ===\")\n",
        "print(f\"S0={S0:.4f}, K={K:.4f}, r={r:.4f}, q={q:.4f}, sigma={sigma:.4f}, T={T:.4f}\")\n",
        "print(f\"P={frozen_ctx['P']}, M={frozen_ctx['M']}, payoff={frozen_ctx['payoff']}\")\n",
        "early_ratio = float((frozen_ctx[\"tau\"] < frozen_ctx[\"M\"]).mean())\n",
        "print(f\"early-exercise ratio ≈ {early_ratio:.3f}\")\n",
        "nbm = frozen_ctx.get(\"near_boundary_mask\", None)\n",
        "if nbm is not None:\n",
        "    print(f\"near-boundary size = {int(nbm.sum())}\")\n",
        "else:\n",
        "    print(\"near-boundary size = N/A\")\n",
        "\n",
        "# --- Timing summary ---\n",
        "print(\"\\n--- Timing (ms) ---\")\n",
        "print(f\"AAD 1st (grads): {t_g1_ep:.1f}   |   FD 1st: {t_g1_fd:.1f}\")\n",
        "print(f\"AAD 2nd (EP):    {t_h2_ep:.1f}   |   FD 2nd:  {t_h2_fd:.1f}\")\n",
        "print(f\"Taylor 2nd:      {t_h2_taylor:.1f}\")\n",
        "\n",
        "# --- First-order Greeks ---\n",
        "df_greeks = pd.concat(\n",
        "    [\n",
        "        pd.Series(g1_ep, index=names_3, name=\"AAD-EP\"),\n",
        "        pd.Series(g1_fd, index=names_3, name=\"FD\"),\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "print(\"\\n--- First-order Greeks (batch-avg) ---\")\n",
        "print(df_greeks.round(6))\n",
        "\n",
        "# --- Second-order Hessians ---\n",
        "df_H_ep = pd.DataFrame(H2_ep, index=names_3, columns=names_3)\n",
        "df_H_fd = pd.DataFrame(H2_fd, index=names_3, columns=names_3)\n",
        "df_H_taylor = pd.DataFrame(H2_taylor, index=names_3, columns=names_3)\n",
        "\n",
        "print(\"\\n--- Second-order Hessian 3×3 (AAD-EP) ---\")\n",
        "print(df_H_ep.round(6))\n",
        "print(\"\\n--- Second-order Hessian 3×3 (FD) ---\")\n",
        "print(df_H_fd.round(6))\n",
        "print(\"\\n--- Second-order Hessian 3×3 (Taylor) ---\")\n",
        "print(df_H_taylor.round(6))\n",
        "\n",
        "# --- Diff matrices ---\n",
        "print(\"\\n--- Diff (Taylor - EP) ---\")\n",
        "print((df_H_taylor - df_H_ep).round(6))\n",
        "print(\"\\n--- Diff (EP - FD) ---\")\n",
        "print((df_H_ep - df_H_fd).round(6))\n",
        "print(\"\\n--- Diff (Taylor - FD) ---\")\n",
        "print((df_H_taylor - df_H_fd).round(6))\n",
        "\n",
        "# --- Max difference summary ---\n",
        "maxdiff_T_EP = np.abs(H2_taylor - H2_ep).max()\n",
        "maxdiff_EP_FD = np.abs(H2_ep - H2_fd).max()\n",
        "maxdiff_T_FD  = np.abs(H2_taylor - H2_fd).max()\n",
        "print(f\"\\nmax|diff(H_Taylor - EP)| = {maxdiff_T_EP:.3e}\")\n",
        "print(f\"max|diff(H_EP - FD)|     = {maxdiff_EP_FD:.3e}\")\n",
        "print(f\"max|diff(H_Taylor - FD)| = {maxdiff_T_FD:.3e}\")\n",
        "\n",
        "# --- Key Greeks summary ---\n",
        "Gamma_E = H2_ep[0, 0];    Vanna_E = H2_ep[0, 1];    Volga_E = H2_ep[1, 1]\n",
        "Gamma_F = H2_fd[0, 0];    Vanna_F = H2_fd[0, 1];    Volga_F = H2_fd[1, 1]\n",
        "Gamma_T = H2_taylor[0, 0]; Vanna_T = H2_taylor[0, 1]; Volga_T = H2_taylor[1, 1]\n",
        "\n",
        "print(f\"\\n[Key Greeks  AAD]   Delta={g1_ep[0]:.4e}, Vega={g1_ep[1]:.4e}, Rho={g1_ep[2]:.4e}\")\n",
        "print(f\"[Key Greeks  AAD]   Gamma={Gamma_E:.4e}, Vanna={Vanna_E:.4e}, Volga={Volga_E:.4e}\")\n",
        "print(f\"[Key Greeks   FD]   Delta={g1_fd[0]:.4e}, Vega={g1_fd[1]:.4e}, Rho={g1_fd[2]:.4e}\")\n",
        "print(f\"[Key Greeks   FD]   Gamma={Gamma_F:.4e}, Vanna={Vanna_F:.4e}, Volga={Volga_F:.4e}\")\n",
        "print(f\"[Key Greeks Taylor] Delta={g1_ep[0]:.4e}, Vega={g1_ep[1]:.4e}, Rho={g1_ep[2]:.4e}\")\n",
        "print(f\"[Key Greeks Taylor] Gamma={Gamma_T:.4e}, Vanna={Vanna_T:.4e}, Volga={Volga_T:.4e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUWbCC0dP2eg",
        "outputId": "ce9dccfd-e002-4579-9581-e681a7480b31"
      },
      "id": "OUWbCC0dP2eg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Run] batch=1000, max_batches=40, cap_active=500, fd1=0.0001, fd2=0.001\n",
            "[Batches] 40 × ~500 ≈ 20000 paths total\n",
            "\n",
            "=== Problem setup (frozen) ===\n",
            "S0=100.0000, K=100.0000, r=0.0300, q=0.0000, sigma=0.2000, T=1.0000\n",
            "P=50000, M=50, payoff=put\n",
            "early-exercise ratio ≈ 0.851\n",
            "near-boundary size = 38900\n",
            "\n",
            "--- Timing (ms) ---\n",
            "AAD 1st (grads): 43562.0   |   FD 1st: 17.2\n",
            "AAD 2nd (EP):    538931.6   |   FD 2nd:  51.6\n",
            "Taylor 2nd:      25307.0\n",
            "\n",
            "--- First-order Greeks (batch-avg) ---\n",
            "          AAD-EP         FD\n",
            "S0      0.581865   0.581865\n",
            "sigma  40.115347  40.115347\n",
            "r     -44.968157 -44.968158\n",
            "\n",
            "--- Second-order Hessian 3×3 (AAD-EP) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Second-order Hessian 3×3 (FD) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160795    0.961112\n",
            "sigma  0.160795  -8.269513  -24.030756\n",
            "r      0.961112 -24.030756  138.539383\n",
            "\n",
            "--- Second-order Hessian 3×3 (Taylor) ---\n",
            "             S0      sigma           r\n",
            "S0     0.009615   0.160793    0.961465\n",
            "sigma  0.160793  -8.269521  -24.036032\n",
            "r      0.961465 -24.036032  138.562860\n",
            "\n",
            "--- Diff (Taylor - EP) ---\n",
            "        S0  sigma    r\n",
            "S0     0.0   -0.0  0.0\n",
            "sigma -0.0    0.0 -0.0\n",
            "r      0.0   -0.0  0.0\n",
            "\n",
            "--- Diff (EP - FD) ---\n",
            "             S0     sigma         r\n",
            "S0     0.000000 -0.000002  0.000353\n",
            "sigma -0.000002 -0.000008 -0.005276\n",
            "r      0.000353 -0.005276  0.023477\n",
            "\n",
            "--- Diff (Taylor - FD) ---\n",
            "             S0     sigma         r\n",
            "S0     0.000000 -0.000002  0.000353\n",
            "sigma -0.000002 -0.000008 -0.005276\n",
            "r      0.000353 -0.005276  0.023477\n",
            "\n",
            "max|diff(H_Taylor - EP)| = 3.695e-13\n",
            "max|diff(H_EP - FD)|     = 2.348e-02\n",
            "max|diff(H_Taylor - FD)| = 2.348e-02\n",
            "\n",
            "[Key Greeks  AAD]   Delta=5.8187e-01, Vega=4.0115e+01, Rho=-4.4968e+01\n",
            "[Key Greeks  AAD]   Gamma=9.6146e-03, Vanna=1.6079e-01, Volga=-8.2695e+00\n",
            "[Key Greeks   FD]   Delta=5.8187e-01, Vega=4.0115e+01, Rho=-4.4968e+01\n",
            "[Key Greeks   FD]   Gamma=9.6146e-03, Vanna=1.6080e-01, Volga=-8.2695e+00\n",
            "[Key Greeks Taylor] Delta=5.8187e-01, Vega=4.0115e+01, Rho=-4.4968e+01\n",
            "[Key Greeks Taylor] Gamma=9.6146e-03, Vanna=1.6079e-01, Volga=-8.2695e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "\n",
        "names_3 = [\"S0\", \"sigma\", \"r\"]\n",
        "\n",
        "# Convert ms → seconds\n",
        "t_ep_2nd  = t_h2_ep     / 1000\n",
        "t_fd_2nd  = t_h2_fd     / 1000\n",
        "t_tay_2nd = t_h2_taylor / 1000\n",
        "\n",
        "df_time = pd.DataFrame({\n",
        "    \"AAD-EP (2nd) Time (s)\": [t_ep_2nd],\n",
        "    \"FD (2nd) Time (s)\":     [t_fd_2nd],\n",
        "    \"Taylor (2nd) Time (s)\": [t_tay_2nd],\n",
        "    \"Speedup EP vs FD\":      [t_fd_2nd / t_ep_2nd],\n",
        "    \"Speedup Taylor vs FD\":  [t_fd_2nd / t_tay_2nd],\n",
        "}, index=[\"Value\"]).round(4)\n",
        "\n",
        "\n",
        "# === Other Results (unchanged) ===\n",
        "df_greeks = pd.DataFrame({\n",
        "    \"AAD-EP\": g1_ep,\n",
        "    \"FD\":     g1_fd\n",
        "}, index=names_3).round(6)\n",
        "\n",
        "df_key = pd.DataFrame({\n",
        "    \"AAD-EP\":  [H2_ep[0,0],  H2_ep[0,1],  H2_ep[1,1]],\n",
        "    \"FD\":      [H2_fd[0,0],  H2_fd[0,1],  H2_fd[1,1]],\n",
        "    \"Taylor\":  [H2_taylor[0,0], H2_taylor[0,1], H2_taylor[1,1]]\n",
        "}, index=[\"Gamma\", \"Vanna\", \"Volga\"]).round(6)\n",
        "\n",
        "df_diff = pd.DataFrame({\n",
        "    \"max|Taylor - EP|\": [np.abs(H2_taylor - H2_ep).max()],\n",
        "    \"max|EP - FD|\":     [np.abs(H2_ep - H2_fd).max()],\n",
        "    \"max|Taylor - FD|\": [np.abs(H2_taylor - H2_fd).max()],\n",
        "}).applymap(lambda x: f\"{x:.3e}\")\n",
        "\n",
        "\n",
        "# ========= Final Print =========\n",
        "print(\"\\n=== 2nd-Order Runtime & Speedup Summary ===\")\n",
        "print(df_time)\n",
        "\n",
        "print(\"\\n=== First-order Greeks (Δ, Vega, Rho) ===\")\n",
        "print(df_greeks)\n",
        "\n",
        "print(\"\\n=== Key 2nd-order Greeks (Gamma, Vanna, Volga) ===\")\n",
        "print(df_key)\n",
        "\n",
        "print(\"\\n=== Maximum Absolute Differences Between Methods ===\")\n",
        "print(df_diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4gYTLIsfKJ4",
        "outputId": "7f61ab7e-1e34-4132-b2ef-b34d9acb822f"
      },
      "id": "o4gYTLIsfKJ4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 2nd-Order Runtime & Speedup Summary ===\n",
            "       AAD-EP (2nd) Time (s)  FD (2nd) Time (s)  Taylor (2nd) Time (s)  \\\n",
            "Value               538.9316             0.0516                 25.307   \n",
            "\n",
            "       Speedup EP vs FD  Speedup Taylor vs FD  \n",
            "Value            0.0001                 0.002  \n",
            "\n",
            "=== First-order Greeks (Δ, Vega, Rho) ===\n",
            "          AAD-EP         FD\n",
            "S0      0.581865   0.581865\n",
            "sigma  40.115347  40.115347\n",
            "r     -44.968157 -44.968158\n",
            "\n",
            "=== Key 2nd-order Greeks (Gamma, Vanna, Volga) ===\n",
            "         AAD-EP        FD    Taylor\n",
            "Gamma  0.009615  0.009615  0.009615\n",
            "Vanna  0.160793  0.160795  0.160793\n",
            "Volga -8.269521 -8.269513 -8.269521\n",
            "\n",
            "=== Maximum Absolute Differences Between Methods ===\n",
            "  max|Taylor - EP| max|EP - FD| max|Taylor - FD|\n",
            "0        3.695e-13    2.348e-02        2.348e-02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1649440470.py:35: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  }).applymap(lambda x: f\"{x:.3e}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "names_3 = [\"S0\", \"sigma\", \"r\"]\n",
        "\n",
        "# ===== 1. Runtime + Speedup 表格（秒） =====\n",
        "# 把 ms 换成 s\n",
        "time_1st_ep  = t_g1_ep      / 1000.0\n",
        "time_1st_fd  = t_g1_fd      / 1000.0\n",
        "time_2nd_ep  = t_h2_ep      / 1000.0\n",
        "time_2nd_fd  = t_h2_fd      / 1000.0\n",
        "time_2nd_tay = t_h2_taylor  / 1000.0\n",
        "\n",
        "df_time = pd.DataFrame({\n",
        "    \"Method\": [\n",
        "        \"AAD-EP (1st)\", \"FD (1st)\",\n",
        "        \"AAD-EP (2nd)\", \"FD (2nd)\", \"Taylor (2nd)\"\n",
        "    ],\n",
        "    \"Order\": [\n",
        "        \"1st\", \"1st\",\n",
        "        \"2nd\", \"2nd\", \"2nd\"\n",
        "    ],\n",
        "    \"Time (s)\": [\n",
        "        time_1st_ep, time_1st_fd,\n",
        "        time_2nd_ep, time_2nd_fd, time_2nd_tay\n",
        "    ]\n",
        "})\n",
        "\n",
        "display(\n",
        "    df_time.style.format({\n",
        "        \"Time (s)\": \"{:.4f}\"\n",
        "    })\n",
        ")\n",
        "\n",
        "\n",
        "# ===== 2. Key Greeks（Δ, Vega, Rho, Gamma, Vanna, Volga）表格 =====\n",
        "Gamma_E = H2_ep[0, 0];    Vanna_E = H2_ep[0, 1];    Volga_E = H2_ep[1, 1]\n",
        "Gamma_F = H2_fd[0, 0];    Vanna_F = H2_fd[0, 1];    Volga_F = H2_fd[1, 1]\n",
        "Gamma_T = H2_taylor[0, 0]; Vanna_T = H2_taylor[0, 1]; Volga_T = H2_taylor[1, 1]\n",
        "\n",
        "df_greeks_all = pd.DataFrame(\n",
        "    data={\n",
        "        \"Delta\": [g1_ep[0],  g1_fd[0],  g1_ep[0]],\n",
        "        \"Vega\":  [g1_ep[1],  g1_fd[1],  g1_ep[1]],\n",
        "        \"Rho\":   [g1_ep[2],  g1_fd[2],  g1_ep[2]],\n",
        "        \"Gamma\": [Gamma_E,   Gamma_F,   Gamma_T],\n",
        "        \"Vanna\": [Vanna_E,   Vanna_F,   Vanna_T],\n",
        "        \"Volga\": [Volga_E,   Volga_F,   Volga_T],\n",
        "    },\n",
        "    index=[\"AAD-EP\", \"FD\", \"Taylor\"]\n",
        ")\n",
        "\n",
        "display(\n",
        "    df_greeks_all.style.format(\"{:.6f}\")\n",
        ")\n",
        "\n",
        "\n",
        "df_H_ep     = pd.DataFrame(H2_ep,     index=names_3, columns=names_3)\n",
        "df_H_fd     = pd.DataFrame(H2_fd,     index=names_3, columns=names_3)\n",
        "df_H_taylor = pd.DataFrame(H2_taylor, index=names_3, columns=names_3)\n",
        "\n",
        "print(\"Hessian (AAD-EP)\")\n",
        "display(df_H_ep.style.format(\"{:.6f}\"))\n",
        "\n",
        "print(\"Hessian (FD)\")\n",
        "display(df_H_fd.style.format(\"{:.6f}\"))\n",
        "\n",
        "print(\"Hessian (Taylor)\")\n",
        "display(df_H_taylor.style.format(\"{:.6f}\"))\n",
        "\n",
        "\n",
        "maxdiff_T_EP = np.abs(H2_taylor - H2_ep).max()\n",
        "maxdiff_EP_FD = np.abs(H2_ep - H2_fd).max()\n",
        "maxdiff_T_FD  = np.abs(H2_taylor - H2_fd).max()\n",
        "\n",
        "df_diff = pd.DataFrame({\n",
        "    \"Pair\": [\"Taylor - EP\", \"EP - FD\", \"Taylor - FD\"],\n",
        "    \"max|diff(H)|\": [maxdiff_T_EP, maxdiff_EP_FD, maxdiff_T_FD],\n",
        "})\n",
        "\n",
        "display(\n",
        "    df_diff.style.format({\"max|diff(H)|\": \"{:.3e}\"})\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "-K4GKOAGg8Kt",
        "outputId": "2f5532b2-97f8-4a4b-d76f-456326736fa2"
      },
      "id": "-K4GKOAGg8Kt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbb4924caa0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_428e7\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_428e7_level0_col0\" class=\"col_heading level0 col0\" >Method</th>\n",
              "      <th id=\"T_428e7_level0_col1\" class=\"col_heading level0 col1\" >Order</th>\n",
              "      <th id=\"T_428e7_level0_col2\" class=\"col_heading level0 col2\" >Time (s)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_428e7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_428e7_row0_col0\" class=\"data row0 col0\" >AAD-EP (1st)</td>\n",
              "      <td id=\"T_428e7_row0_col1\" class=\"data row0 col1\" >1st</td>\n",
              "      <td id=\"T_428e7_row0_col2\" class=\"data row0 col2\" >43.5620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_428e7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_428e7_row1_col0\" class=\"data row1 col0\" >FD (1st)</td>\n",
              "      <td id=\"T_428e7_row1_col1\" class=\"data row1 col1\" >1st</td>\n",
              "      <td id=\"T_428e7_row1_col2\" class=\"data row1 col2\" >0.0172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_428e7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_428e7_row2_col0\" class=\"data row2 col0\" >AAD-EP (2nd)</td>\n",
              "      <td id=\"T_428e7_row2_col1\" class=\"data row2 col1\" >2nd</td>\n",
              "      <td id=\"T_428e7_row2_col2\" class=\"data row2 col2\" >538.9316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_428e7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_428e7_row3_col0\" class=\"data row3 col0\" >FD (2nd)</td>\n",
              "      <td id=\"T_428e7_row3_col1\" class=\"data row3 col1\" >2nd</td>\n",
              "      <td id=\"T_428e7_row3_col2\" class=\"data row3 col2\" >0.0516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_428e7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_428e7_row4_col0\" class=\"data row4 col0\" >Taylor (2nd)</td>\n",
              "      <td id=\"T_428e7_row4_col1\" class=\"data row4 col1\" >2nd</td>\n",
              "      <td id=\"T_428e7_row4_col2\" class=\"data row4 col2\" >25.3070</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbb52b68da0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_c8078\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_c8078_level0_col0\" class=\"col_heading level0 col0\" >Delta</th>\n",
              "      <th id=\"T_c8078_level0_col1\" class=\"col_heading level0 col1\" >Vega</th>\n",
              "      <th id=\"T_c8078_level0_col2\" class=\"col_heading level0 col2\" >Rho</th>\n",
              "      <th id=\"T_c8078_level0_col3\" class=\"col_heading level0 col3\" >Gamma</th>\n",
              "      <th id=\"T_c8078_level0_col4\" class=\"col_heading level0 col4\" >Vanna</th>\n",
              "      <th id=\"T_c8078_level0_col5\" class=\"col_heading level0 col5\" >Volga</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_c8078_level0_row0\" class=\"row_heading level0 row0\" >AAD-EP</th>\n",
              "      <td id=\"T_c8078_row0_col0\" class=\"data row0 col0\" >0.581865</td>\n",
              "      <td id=\"T_c8078_row0_col1\" class=\"data row0 col1\" >40.115347</td>\n",
              "      <td id=\"T_c8078_row0_col2\" class=\"data row0 col2\" >-44.968157</td>\n",
              "      <td id=\"T_c8078_row0_col3\" class=\"data row0 col3\" >0.009615</td>\n",
              "      <td id=\"T_c8078_row0_col4\" class=\"data row0 col4\" >0.160793</td>\n",
              "      <td id=\"T_c8078_row0_col5\" class=\"data row0 col5\" >-8.269521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8078_level0_row1\" class=\"row_heading level0 row1\" >FD</th>\n",
              "      <td id=\"T_c8078_row1_col0\" class=\"data row1 col0\" >0.581865</td>\n",
              "      <td id=\"T_c8078_row1_col1\" class=\"data row1 col1\" >40.115347</td>\n",
              "      <td id=\"T_c8078_row1_col2\" class=\"data row1 col2\" >-44.968158</td>\n",
              "      <td id=\"T_c8078_row1_col3\" class=\"data row1 col3\" >0.009615</td>\n",
              "      <td id=\"T_c8078_row1_col4\" class=\"data row1 col4\" >0.160795</td>\n",
              "      <td id=\"T_c8078_row1_col5\" class=\"data row1 col5\" >-8.269513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_c8078_level0_row2\" class=\"row_heading level0 row2\" >Taylor</th>\n",
              "      <td id=\"T_c8078_row2_col0\" class=\"data row2 col0\" >0.581865</td>\n",
              "      <td id=\"T_c8078_row2_col1\" class=\"data row2 col1\" >40.115347</td>\n",
              "      <td id=\"T_c8078_row2_col2\" class=\"data row2 col2\" >-44.968157</td>\n",
              "      <td id=\"T_c8078_row2_col3\" class=\"data row2 col3\" >0.009615</td>\n",
              "      <td id=\"T_c8078_row2_col4\" class=\"data row2 col4\" >0.160793</td>\n",
              "      <td id=\"T_c8078_row2_col5\" class=\"data row2 col5\" >-8.269521</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hessian (AAD-EP)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbafb6b0350>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_84c9c\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_84c9c_level0_col0\" class=\"col_heading level0 col0\" >S0</th>\n",
              "      <th id=\"T_84c9c_level0_col1\" class=\"col_heading level0 col1\" >sigma</th>\n",
              "      <th id=\"T_84c9c_level0_col2\" class=\"col_heading level0 col2\" >r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_84c9c_level0_row0\" class=\"row_heading level0 row0\" >S0</th>\n",
              "      <td id=\"T_84c9c_row0_col0\" class=\"data row0 col0\" >0.009615</td>\n",
              "      <td id=\"T_84c9c_row0_col1\" class=\"data row0 col1\" >0.160793</td>\n",
              "      <td id=\"T_84c9c_row0_col2\" class=\"data row0 col2\" >0.961465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_84c9c_level0_row1\" class=\"row_heading level0 row1\" >sigma</th>\n",
              "      <td id=\"T_84c9c_row1_col0\" class=\"data row1 col0\" >0.160793</td>\n",
              "      <td id=\"T_84c9c_row1_col1\" class=\"data row1 col1\" >-8.269521</td>\n",
              "      <td id=\"T_84c9c_row1_col2\" class=\"data row1 col2\" >-24.036032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_84c9c_level0_row2\" class=\"row_heading level0 row2\" >r</th>\n",
              "      <td id=\"T_84c9c_row2_col0\" class=\"data row2 col0\" >0.961465</td>\n",
              "      <td id=\"T_84c9c_row2_col1\" class=\"data row2 col1\" >-24.036032</td>\n",
              "      <td id=\"T_84c9c_row2_col2\" class=\"data row2 col2\" >138.562860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hessian (FD)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbafb6b38f0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_b652d\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_b652d_level0_col0\" class=\"col_heading level0 col0\" >S0</th>\n",
              "      <th id=\"T_b652d_level0_col1\" class=\"col_heading level0 col1\" >sigma</th>\n",
              "      <th id=\"T_b652d_level0_col2\" class=\"col_heading level0 col2\" >r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_b652d_level0_row0\" class=\"row_heading level0 row0\" >S0</th>\n",
              "      <td id=\"T_b652d_row0_col0\" class=\"data row0 col0\" >0.009615</td>\n",
              "      <td id=\"T_b652d_row0_col1\" class=\"data row0 col1\" >0.160795</td>\n",
              "      <td id=\"T_b652d_row0_col2\" class=\"data row0 col2\" >0.961112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b652d_level0_row1\" class=\"row_heading level0 row1\" >sigma</th>\n",
              "      <td id=\"T_b652d_row1_col0\" class=\"data row1 col0\" >0.160795</td>\n",
              "      <td id=\"T_b652d_row1_col1\" class=\"data row1 col1\" >-8.269513</td>\n",
              "      <td id=\"T_b652d_row1_col2\" class=\"data row1 col2\" >-24.030756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_b652d_level0_row2\" class=\"row_heading level0 row2\" >r</th>\n",
              "      <td id=\"T_b652d_row2_col0\" class=\"data row2 col0\" >0.961112</td>\n",
              "      <td id=\"T_b652d_row2_col1\" class=\"data row2 col1\" >-24.030756</td>\n",
              "      <td id=\"T_b652d_row2_col2\" class=\"data row2 col2\" >138.539383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hessian (Taylor)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbb4b4936e0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_94370\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_94370_level0_col0\" class=\"col_heading level0 col0\" >S0</th>\n",
              "      <th id=\"T_94370_level0_col1\" class=\"col_heading level0 col1\" >sigma</th>\n",
              "      <th id=\"T_94370_level0_col2\" class=\"col_heading level0 col2\" >r</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_94370_level0_row0\" class=\"row_heading level0 row0\" >S0</th>\n",
              "      <td id=\"T_94370_row0_col0\" class=\"data row0 col0\" >0.009615</td>\n",
              "      <td id=\"T_94370_row0_col1\" class=\"data row0 col1\" >0.160793</td>\n",
              "      <td id=\"T_94370_row0_col2\" class=\"data row0 col2\" >0.961465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_94370_level0_row1\" class=\"row_heading level0 row1\" >sigma</th>\n",
              "      <td id=\"T_94370_row1_col0\" class=\"data row1 col0\" >0.160793</td>\n",
              "      <td id=\"T_94370_row1_col1\" class=\"data row1 col1\" >-8.269521</td>\n",
              "      <td id=\"T_94370_row1_col2\" class=\"data row1 col2\" >-24.036032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_94370_level0_row2\" class=\"row_heading level0 row2\" >r</th>\n",
              "      <td id=\"T_94370_row2_col0\" class=\"data row2 col0\" >0.961465</td>\n",
              "      <td id=\"T_94370_row2_col1\" class=\"data row2 col1\" >-24.036032</td>\n",
              "      <td id=\"T_94370_row2_col2\" class=\"data row2 col2\" >138.562860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbb1d620a10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_177c1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_177c1_level0_col0\" class=\"col_heading level0 col0\" >Pair</th>\n",
              "      <th id=\"T_177c1_level0_col1\" class=\"col_heading level0 col1\" >max|diff(H)|</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_177c1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_177c1_row0_col0\" class=\"data row0 col0\" >Taylor - EP</td>\n",
              "      <td id=\"T_177c1_row0_col1\" class=\"data row0 col1\" >3.695e-13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_177c1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_177c1_row1_col0\" class=\"data row1 col0\" >EP - FD</td>\n",
              "      <td id=\"T_177c1_row1_col1\" class=\"data row1 col1\" >2.348e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_177c1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_177c1_row2_col0\" class=\"data row2 col0\" >Taylor - FD</td>\n",
              "      <td id=\"T_177c1_row2_col1\" class=\"data row2 col1\" >2.348e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# === Key Greeks ===\n",
        "Gamma_E = H2_ep[0, 0];    Vanna_E = H2_ep[0, 1];    Volga_E = H2_ep[1, 1]\n",
        "Gamma_F = H2_fd[0, 0];    Vanna_F = H2_fd[0, 1];    Volga_F = H2_fd[1, 1]\n",
        "Gamma_T = H2_taylor[0, 0]; Vanna_T = H2_taylor[0, 1]; Volga_T = H2_taylor[1, 1]\n",
        "\n",
        "# === Hessian max-diff ===\n",
        "maxdiff_T_EP = np.abs(H2_taylor - H2_ep).max()\n",
        "maxdiff_EP_FD = np.abs(H2_ep - H2_fd).max()\n",
        "maxdiff_T_FD  = np.abs(H2_taylor - H2_fd).max()\n",
        "\n",
        "df_greeks_all = pd.DataFrame(\n",
        "    data={\n",
        "        \"Delta\": [g1_ep[0],  g1_fd[0],  g1_ep[0]],\n",
        "        \"Vega\":  [g1_ep[1],  g1_fd[1],  g1_ep[1]],\n",
        "        \"Rho\":   [g1_ep[2],  g1_fd[2],  g1_ep[2]],\n",
        "        \"Gamma\": [Gamma_E,   Gamma_F,   Gamma_T],\n",
        "        \"Vanna\": [Vanna_E,   Vanna_F,   Vanna_T],\n",
        "        \"Volga\": [Volga_E,   Volga_F,   Volga_T],\n",
        "        \"max|diff(H) vs EP|\": [\n",
        "            None,               # EP baseline\n",
        "            maxdiff_EP_FD,      # FD\n",
        "            maxdiff_T_EP        # Taylor\n",
        "        ],\n",
        "        \"max|diff(H) vs FD|\": [\n",
        "            maxdiff_EP_FD,      # EP\n",
        "            None,               # FD baseline\n",
        "            maxdiff_T_FD        # Taylor\n",
        "        ],\n",
        "    },\n",
        "    index=[\"AAD-EP\", \"FD\", \"Taylor\"]\n",
        ")\n",
        "\n",
        "display(\n",
        "    df_greeks_all.style.format({\n",
        "        \"Delta\": \"{:.6f}\", \"Vega\": \"{:.6f}\", \"Rho\": \"{:.6f}\",\n",
        "        \"Gamma\": \"{:.6f}\", \"Vanna\": \"{:.6f}\", \"Volga\": \"{:.6f}\",\n",
        "        \"max|diff(H) vs EP|\": \"{:.3e}\",\n",
        "        \"max|diff(H) vs FD|\": \"{:.3e}\",\n",
        "    }).set_properties(**{\"text-align\": \"center\"})\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "W5K_n-5cirfK",
        "outputId": "c02da4e0-7ee6-4a6f-c97c-e9bfb9797ca0"
      },
      "id": "W5K_n-5cirfK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7cbb1d620860>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_ec1a2_row0_col0, #T_ec1a2_row0_col1, #T_ec1a2_row0_col2, #T_ec1a2_row0_col3, #T_ec1a2_row0_col4, #T_ec1a2_row0_col5, #T_ec1a2_row0_col6, #T_ec1a2_row0_col7, #T_ec1a2_row1_col0, #T_ec1a2_row1_col1, #T_ec1a2_row1_col2, #T_ec1a2_row1_col3, #T_ec1a2_row1_col4, #T_ec1a2_row1_col5, #T_ec1a2_row1_col6, #T_ec1a2_row1_col7, #T_ec1a2_row2_col0, #T_ec1a2_row2_col1, #T_ec1a2_row2_col2, #T_ec1a2_row2_col3, #T_ec1a2_row2_col4, #T_ec1a2_row2_col5, #T_ec1a2_row2_col6, #T_ec1a2_row2_col7 {\n",
              "  text-align: center;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ec1a2\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_ec1a2_level0_col0\" class=\"col_heading level0 col0\" >Delta</th>\n",
              "      <th id=\"T_ec1a2_level0_col1\" class=\"col_heading level0 col1\" >Vega</th>\n",
              "      <th id=\"T_ec1a2_level0_col2\" class=\"col_heading level0 col2\" >Rho</th>\n",
              "      <th id=\"T_ec1a2_level0_col3\" class=\"col_heading level0 col3\" >Gamma</th>\n",
              "      <th id=\"T_ec1a2_level0_col4\" class=\"col_heading level0 col4\" >Vanna</th>\n",
              "      <th id=\"T_ec1a2_level0_col5\" class=\"col_heading level0 col5\" >Volga</th>\n",
              "      <th id=\"T_ec1a2_level0_col6\" class=\"col_heading level0 col6\" >max|diff(H) vs EP|</th>\n",
              "      <th id=\"T_ec1a2_level0_col7\" class=\"col_heading level0 col7\" >max|diff(H) vs FD|</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_ec1a2_level0_row0\" class=\"row_heading level0 row0\" >AAD-EP</th>\n",
              "      <td id=\"T_ec1a2_row0_col0\" class=\"data row0 col0\" >0.581865</td>\n",
              "      <td id=\"T_ec1a2_row0_col1\" class=\"data row0 col1\" >40.115347</td>\n",
              "      <td id=\"T_ec1a2_row0_col2\" class=\"data row0 col2\" >-44.968157</td>\n",
              "      <td id=\"T_ec1a2_row0_col3\" class=\"data row0 col3\" >0.009615</td>\n",
              "      <td id=\"T_ec1a2_row0_col4\" class=\"data row0 col4\" >0.160793</td>\n",
              "      <td id=\"T_ec1a2_row0_col5\" class=\"data row0 col5\" >-8.269521</td>\n",
              "      <td id=\"T_ec1a2_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
              "      <td id=\"T_ec1a2_row0_col7\" class=\"data row0 col7\" >2.348e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ec1a2_level0_row1\" class=\"row_heading level0 row1\" >FD</th>\n",
              "      <td id=\"T_ec1a2_row1_col0\" class=\"data row1 col0\" >0.581865</td>\n",
              "      <td id=\"T_ec1a2_row1_col1\" class=\"data row1 col1\" >40.115347</td>\n",
              "      <td id=\"T_ec1a2_row1_col2\" class=\"data row1 col2\" >-44.968158</td>\n",
              "      <td id=\"T_ec1a2_row1_col3\" class=\"data row1 col3\" >0.009615</td>\n",
              "      <td id=\"T_ec1a2_row1_col4\" class=\"data row1 col4\" >0.160795</td>\n",
              "      <td id=\"T_ec1a2_row1_col5\" class=\"data row1 col5\" >-8.269513</td>\n",
              "      <td id=\"T_ec1a2_row1_col6\" class=\"data row1 col6\" >2.348e-02</td>\n",
              "      <td id=\"T_ec1a2_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_ec1a2_level0_row2\" class=\"row_heading level0 row2\" >Taylor</th>\n",
              "      <td id=\"T_ec1a2_row2_col0\" class=\"data row2 col0\" >0.581865</td>\n",
              "      <td id=\"T_ec1a2_row2_col1\" class=\"data row2 col1\" >40.115347</td>\n",
              "      <td id=\"T_ec1a2_row2_col2\" class=\"data row2 col2\" >-44.968157</td>\n",
              "      <td id=\"T_ec1a2_row2_col3\" class=\"data row2 col3\" >0.009615</td>\n",
              "      <td id=\"T_ec1a2_row2_col4\" class=\"data row2 col4\" >0.160793</td>\n",
              "      <td id=\"T_ec1a2_row2_col5\" class=\"data row2 col5\" >-8.269521</td>\n",
              "      <td id=\"T_ec1a2_row2_col6\" class=\"data row2 col6\" >3.695e-13</td>\n",
              "      <td id=\"T_ec1a2_row2_col7\" class=\"data row2 col7\" >2.348e-02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}